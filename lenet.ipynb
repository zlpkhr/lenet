{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5 Fault Injection\n",
    "\n",
    "This code implements fault injection testing on a quantized LeNet-5 convolutional neural network using PyTorch. The network is trained on the MNIST dataset, quantized to 8-bit integers, and systematically tested by flipping individual bits in its parameters. The testing framework allows both random bit flips across all layers and targeted testing of specific layers and bit positions, measuring how these faults impact the model's classification accuracy.\n",
    "\n",
    "![framework](framework.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python and PyTorch make it easy to modify neural network parameters during runtime testing. PyTorch directly exposes quantized weights through its API, while TensorFlow doesn't allow modifying weights after quantization. Using established ML frameworks like PyTorch also leverages years of development and testing by the community, saving time and avoiding common pitfalls that others have already solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch requires defining forward to specify data flow through network layers - it's called automatically when you run lenet(input). The code inherits from nn.Module for automatic gradient computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Lenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.s2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.c3 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.s4 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.f5 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.f6 = nn.Linear(120, 84)\n",
    "        self.f7 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.c1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.s2(x)\n",
    "        x = self.c3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.s4(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.f5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.f6(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.f7(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "lenet = Lenet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets up data loading for the MNIST dataset. `NUM_WORKERS` is set to optimize CPU usage (max 4 threads) and batch size is 64. The transforms prep images by:\n",
    "- Converting to tensors\n",
    "- Normalizing with MNIST's mean (0.1307) and std (0.3081) \n",
    "- Adding 2-pixel padding to match LeNet input size\n",
    "\n",
    "The MNIST dataset is downloaded and split:\n",
    "- Test set (standard split)\n",
    "- Training set split into 80% train, 20% validation\n",
    "\n",
    "`DataLoader` wraps these datasets to enable batch processing with specified workers. Training data is shuffled, validation/test aren't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "NUM_WORKERS = min(4, os.cpu_count())\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "transform = T.Compose(\n",
    "    [\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.1307,), (0.3081,)),\n",
    "        T.Pad(2),\n",
    "    ]\n",
    ")\n",
    "train_set = datasets.MNIST(\"tmp/data\", train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST(\"tmp/data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(train_set))\n",
    "val_size = len(train_set) - train_size\n",
    "\n",
    "train_set, val_set = random_split(train_set, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_set, BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "exp_loader = DataLoader(test_set, BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function evaluates model accuracy by running inference in evaluation mode (`model.eval()`), disabling gradients for efficiency, and calculating the percentage of correct predictions by comparing model outputs against target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model: nn.Module, loader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    total = correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input, target in loader:\n",
    "            output = model(input)\n",
    "            pred = torch.argmax(output, dim=1)\n",
    "            total += target.size(0)\n",
    "            correct += (pred == target).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop running for 3 epochs using Adam optimizer with learning rate 0.01. Each iteration zeros gradients, runs forward pass through LeNet, calculates cross-entropy loss between predictions and targets, backpropagates gradients (loss.backward()), and updates model weights (optimizer.step()). Progress prints every 100 batches. Finally tests model accuracy on test set using previously defined calculate_accuracy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINING] epoch=1 batch=0 loss=2.30\n",
      "[TRAINING] epoch=1 batch=100 loss=0.03\n",
      "[TRAINING] epoch=1 batch=200 loss=0.10\n",
      "[TRAINING] epoch=1 batch=300 loss=0.09\n",
      "[TRAINING] epoch=1 batch=400 loss=0.15\n",
      "[TRAINING] epoch=1 batch=500 loss=0.12\n",
      "[TRAINING] epoch=1 batch=600 loss=0.10\n",
      "[TRAINING] epoch=1 batch=700 loss=0.11\n",
      "[TRAINING] epoch=2 batch=0 loss=0.09\n",
      "[TRAINING] epoch=2 batch=100 loss=0.03\n",
      "[TRAINING] epoch=2 batch=200 loss=0.21\n",
      "[TRAINING] epoch=2 batch=300 loss=0.04\n",
      "[TRAINING] epoch=2 batch=400 loss=0.06\n",
      "[TRAINING] epoch=2 batch=500 loss=0.06\n",
      "[TRAINING] epoch=2 batch=600 loss=0.08\n",
      "[TRAINING] epoch=2 batch=700 loss=0.05\n",
      "[TRAINING] epoch=3 batch=0 loss=0.12\n",
      "[TRAINING] epoch=3 batch=100 loss=0.01\n",
      "[TRAINING] epoch=3 batch=200 loss=0.20\n",
      "[TRAINING] epoch=3 batch=300 loss=0.07\n",
      "[TRAINING] epoch=3 batch=400 loss=0.08\n",
      "[TRAINING] epoch=3 batch=500 loss=0.12\n",
      "[TRAINING] epoch=3 batch=600 loss=0.19\n",
      "[TRAINING] epoch=3 batch=700 loss=0.01\n",
      "[TESTING] accuracy=98.21%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "optimizer = optim.Adam(lenet.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "lenet.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (input, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        flip_output = lenet(input)\n",
    "        loss = F.cross_entropy(flip_output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"[TRAINING] epoch={epoch + 1} batch={batch_idx} loss={loss.item():.2f}\"\n",
    "            )\n",
    "\n",
    "\n",
    "print(f\"[TESTING] accuracy={(100 * calculate_accuracy(lenet, exp_loader)):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves trained LeNet model's parameters (weights and biases) to a file named \"lenet.pt\" using PyTorch's save function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENET_PATH = \"lenet.pt\"\n",
    "\n",
    "torch.save(lenet.state_dict(), LENET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a quantization-ready version of LeNet by subclassing it. QLenet adds quantization (QuantStub) and dequantization (DeQuantStub) layers around the original network's forward pass. These stubs mark where PyTorch should convert between floating-point and quantized (8-bit integer) representations. The model loads weights from the previously saved LeNet using load_state_dict, with weights_only=True to ignore any saved optimizer state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "\n",
    "\n",
    "class QLenet(Lenet):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.quant(x)\n",
    "        x = super().forward(x)\n",
    "        x = self.dequant(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "qlenet = QLenet()\n",
    "\n",
    "qlenet.load_state_dict(torch.load(LENET_PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code configures quantization using Facebook's FBGEMM backend, prepares the model for quantization, then calibrates it by running validation data through the network to collect statistics about activation ranges. Finally, it converts the model to use quantized (8-bit) weights and tests its accuracy. The `inplace=True` parameter modifies the model directly instead of creating copies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/lenet/.venv/lib/python3.11/site-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CALIBRATING] batch=0\n",
      "[CALIBRATING] batch=1\n",
      "[CALIBRATING] batch=2\n",
      "[CALIBRATING] batch=3\n",
      "[CALIBRATING] batch=4\n",
      "[CALIBRATING] batch=5\n",
      "[CALIBRATING] batch=6\n",
      "[CALIBRATING] batch=7\n",
      "[CALIBRATING] batch=8\n",
      "[CALIBRATING] batch=9\n",
      "[CALIBRATING] batch=10\n",
      "[CALIBRATING] batch=11\n",
      "[CALIBRATING] batch=12\n",
      "[CALIBRATING] batch=13\n",
      "[CALIBRATING] batch=14\n",
      "[CALIBRATING] batch=15\n",
      "[CALIBRATING] batch=16\n",
      "[CALIBRATING] batch=17\n",
      "[CALIBRATING] batch=18\n",
      "[CALIBRATING] batch=19\n",
      "[CALIBRATING] batch=20\n",
      "[CALIBRATING] batch=21\n",
      "[CALIBRATING] batch=22\n",
      "[CALIBRATING] batch=23\n",
      "[CALIBRATING] batch=24\n",
      "[CALIBRATING] batch=25\n",
      "[CALIBRATING] batch=26\n",
      "[CALIBRATING] batch=27\n",
      "[CALIBRATING] batch=28\n",
      "[CALIBRATING] batch=29\n",
      "[CALIBRATING] batch=30\n",
      "[CALIBRATING] batch=31\n",
      "[CALIBRATING] batch=32\n",
      "[CALIBRATING] batch=33\n",
      "[CALIBRATING] batch=34\n",
      "[CALIBRATING] batch=35\n",
      "[CALIBRATING] batch=36\n",
      "[CALIBRATING] batch=37\n",
      "[CALIBRATING] batch=38\n",
      "[CALIBRATING] batch=39\n",
      "[CALIBRATING] batch=40\n",
      "[CALIBRATING] batch=41\n",
      "[CALIBRATING] batch=42\n",
      "[CALIBRATING] batch=43\n",
      "[CALIBRATING] batch=44\n",
      "[CALIBRATING] batch=45\n",
      "[CALIBRATING] batch=46\n",
      "[CALIBRATING] batch=47\n",
      "[CALIBRATING] batch=48\n",
      "[CALIBRATING] batch=49\n",
      "[CALIBRATING] batch=50\n",
      "[CALIBRATING] batch=51\n",
      "[CALIBRATING] batch=52\n",
      "[CALIBRATING] batch=53\n",
      "[CALIBRATING] batch=54\n",
      "[CALIBRATING] batch=55\n",
      "[CALIBRATING] batch=56\n",
      "[CALIBRATING] batch=57\n",
      "[CALIBRATING] batch=58\n",
      "[CALIBRATING] batch=59\n",
      "[CALIBRATING] batch=60\n",
      "[CALIBRATING] batch=61\n",
      "[CALIBRATING] batch=62\n",
      "[CALIBRATING] batch=63\n",
      "[CALIBRATING] batch=64\n",
      "[CALIBRATING] batch=65\n",
      "[CALIBRATING] batch=66\n",
      "[CALIBRATING] batch=67\n",
      "[CALIBRATING] batch=68\n",
      "[CALIBRATING] batch=69\n",
      "[CALIBRATING] batch=70\n",
      "[CALIBRATING] batch=71\n",
      "[CALIBRATING] batch=72\n",
      "[CALIBRATING] batch=73\n",
      "[CALIBRATING] batch=74\n",
      "[CALIBRATING] batch=75\n",
      "[CALIBRATING] batch=76\n",
      "[CALIBRATING] batch=77\n",
      "[CALIBRATING] batch=78\n",
      "[CALIBRATING] batch=79\n",
      "[CALIBRATING] batch=80\n",
      "[CALIBRATING] batch=81\n",
      "[CALIBRATING] batch=82\n",
      "[CALIBRATING] batch=83\n",
      "[CALIBRATING] batch=84\n",
      "[CALIBRATING] batch=85\n",
      "[CALIBRATING] batch=86\n",
      "[CALIBRATING] batch=87\n",
      "[CALIBRATING] batch=88\n",
      "[CALIBRATING] batch=89\n",
      "[CALIBRATING] batch=90\n",
      "[CALIBRATING] batch=91\n",
      "[CALIBRATING] batch=92\n",
      "[CALIBRATING] batch=93\n",
      "[CALIBRATING] batch=94\n",
      "[CALIBRATING] batch=95\n",
      "[CALIBRATING] batch=96\n",
      "[CALIBRATING] batch=97\n",
      "[CALIBRATING] batch=98\n",
      "[CALIBRATING] batch=99\n",
      "[CALIBRATING] batch=100\n",
      "[CALIBRATING] batch=101\n",
      "[CALIBRATING] batch=102\n",
      "[CALIBRATING] batch=103\n",
      "[CALIBRATING] batch=104\n",
      "[CALIBRATING] batch=105\n",
      "[CALIBRATING] batch=106\n",
      "[CALIBRATING] batch=107\n",
      "[CALIBRATING] batch=108\n",
      "[CALIBRATING] batch=109\n",
      "[CALIBRATING] batch=110\n",
      "[CALIBRATING] batch=111\n",
      "[CALIBRATING] batch=112\n",
      "[CALIBRATING] batch=113\n",
      "[CALIBRATING] batch=114\n",
      "[CALIBRATING] batch=115\n",
      "[CALIBRATING] batch=116\n",
      "[CALIBRATING] batch=117\n",
      "[CALIBRATING] batch=118\n",
      "[CALIBRATING] batch=119\n",
      "[CALIBRATING] batch=120\n",
      "[CALIBRATING] batch=121\n",
      "[CALIBRATING] batch=122\n",
      "[CALIBRATING] batch=123\n",
      "[CALIBRATING] batch=124\n",
      "[CALIBRATING] batch=125\n",
      "[CALIBRATING] batch=126\n",
      "[CALIBRATING] batch=127\n",
      "[CALIBRATING] batch=128\n",
      "[CALIBRATING] batch=129\n",
      "[CALIBRATING] batch=130\n",
      "[CALIBRATING] batch=131\n",
      "[CALIBRATING] batch=132\n",
      "[CALIBRATING] batch=133\n",
      "[CALIBRATING] batch=134\n",
      "[CALIBRATING] batch=135\n",
      "[CALIBRATING] batch=136\n",
      "[CALIBRATING] batch=137\n",
      "[CALIBRATING] batch=138\n",
      "[CALIBRATING] batch=139\n",
      "[CALIBRATING] batch=140\n",
      "[CALIBRATING] batch=141\n",
      "[CALIBRATING] batch=142\n",
      "[CALIBRATING] batch=143\n",
      "[CALIBRATING] batch=144\n",
      "[CALIBRATING] batch=145\n",
      "[CALIBRATING] batch=146\n",
      "[CALIBRATING] batch=147\n",
      "[CALIBRATING] batch=148\n",
      "[CALIBRATING] batch=149\n",
      "[CALIBRATING] batch=150\n",
      "[CALIBRATING] batch=151\n",
      "[CALIBRATING] batch=152\n",
      "[CALIBRATING] batch=153\n",
      "[CALIBRATING] batch=154\n",
      "[CALIBRATING] batch=155\n",
      "[CALIBRATING] batch=156\n",
      "[CALIBRATING] batch=157\n",
      "[CALIBRATING] batch=158\n",
      "[CALIBRATING] batch=159\n",
      "[CALIBRATING] batch=160\n",
      "[CALIBRATING] batch=161\n",
      "[CALIBRATING] batch=162\n",
      "[CALIBRATING] batch=163\n",
      "[CALIBRATING] batch=164\n",
      "[CALIBRATING] batch=165\n",
      "[CALIBRATING] batch=166\n",
      "[CALIBRATING] batch=167\n",
      "[CALIBRATING] batch=168\n",
      "[CALIBRATING] batch=169\n",
      "[CALIBRATING] batch=170\n",
      "[CALIBRATING] batch=171\n",
      "[CALIBRATING] batch=172\n",
      "[CALIBRATING] batch=173\n",
      "[CALIBRATING] batch=174\n",
      "[CALIBRATING] batch=175\n",
      "[CALIBRATING] batch=176\n",
      "[CALIBRATING] batch=177\n",
      "[CALIBRATING] batch=178\n",
      "[CALIBRATING] batch=179\n",
      "[CALIBRATING] batch=180\n",
      "[CALIBRATING] batch=181\n",
      "[CALIBRATING] batch=182\n",
      "[CALIBRATING] batch=183\n",
      "[CALIBRATING] batch=184\n",
      "[CALIBRATING] batch=185\n",
      "[CALIBRATING] batch=186\n",
      "[CALIBRATING] batch=187\n",
      "[TESTING] accuracy=98.05%\n"
     ]
    }
   ],
   "source": [
    "import torch.quantization as quantization\n",
    "\n",
    "BACKEND = \"fbgemm\"\n",
    "\n",
    "qlenet.qconfig = quantization.get_default_qconfig(BACKEND)\n",
    "quantization.prepare(qlenet, inplace=True)\n",
    "\n",
    "qlenet.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (input, _) in enumerate(val_loader):\n",
    "        qlenet(input)\n",
    "        print(f\"[CALIBRATING] batch={batch_idx}\")\n",
    "\n",
    "quantization.convert(qlenet, inplace=True)\n",
    "\n",
    "quant_accuracy = 100 * calculate_accuracy(qlenet, exp_loader)\n",
    "print(f\"[TESTING] accuracy={quant_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves the quantized LeNet model's state dictionary to \"qlenet.pt\" file, preserving the quantized weights and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "QLENET_PATH = \"qlenet.pt\"\n",
    "\n",
    "torch.save(qlenet.state_dict(), QLENET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code recreates a new quantization-ready LeNet (flenet), prepares and converts it for quantization without calibration, then loads the previously saved quantized weights from \"qlenet.pt\". This way the model starts directly with quantized weights instead of needing recalibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/lenet/.venv/lib/python3.11/site-packages/torch/ao/quantization/observer.py:1315: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n",
      "/workspaces/lenet/.venv/lib/python3.11/site-packages/torch/_utils.py:413: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flenet = QLenet()\n",
    "\n",
    "flenet.qconfig = quantization.get_default_qconfig(BACKEND)\n",
    "quantization.prepare(flenet, inplace=True)\n",
    "quantization.convert(flenet, inplace=True)\n",
    "\n",
    "flenet.load_state_dict(torch.load(QLENET_PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are utility functions for manipulating quantized model weights, including bit flipping, layer selection, tensor conversion, and quantization operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Tuple\n",
    "import numpy as np\n",
    "from torch import quantize_per_tensor\n",
    "import random\n",
    "\n",
    "\n",
    "def get_weight_key(model: nn.Module, attr: str) -> str:\n",
    "    \"\"\"Retrieves the appropriate weight key for accessing model parameters based on layer type.\n",
    "\n",
    "    Args:\n",
    "        model: Neural network module\n",
    "        attr: Layer attribute name\n",
    "\n",
    "    Returns:\n",
    "        String key to access weights in state dict\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If layer type is not supported (not Conv2d or Linear)\n",
    "    \"\"\"\n",
    "    module = getattr(model, attr)\n",
    "    if isinstance(module, torch.ao.nn.quantized.modules.conv.Conv2d):\n",
    "        return f\"{attr}.weight\"\n",
    "    elif isinstance(module, torch.ao.nn.quantized.modules.linear.Linear):\n",
    "        return f\"{attr}._packed_params._packed_params\"\n",
    "    raise ValueError(f\"Unsupported module type: {type(module)}\")\n",
    "\n",
    "\n",
    "def get_bit(byte: np.int8, pos: int) -> np.int8:\n",
    "    \"\"\"Extracts the bit at specified position from an 8-bit integer.\n",
    "\n",
    "    Args:\n",
    "        byte: 8-bit integer input\n",
    "        pos: Bit position to extract (0-7)\n",
    "\n",
    "    Returns:\n",
    "        Value of bit at specified position (0 or 1)\n",
    "    \"\"\"\n",
    "    return np.bitwise_and(np.right_shift(byte, pos), np.int8(1))\n",
    "\n",
    "\n",
    "def flip_bit(byte: np.int8, pos: int) -> np.int8:\n",
    "    \"\"\"Flips (inverts) the bit at specified position in an 8-bit integer.\n",
    "\n",
    "    Args:\n",
    "        byte: 8-bit integer input\n",
    "        pos: Position of bit to flip (0-7)\n",
    "\n",
    "    Returns:\n",
    "        New 8-bit integer with specified bit flipped\n",
    "    \"\"\"\n",
    "    return np.bitwise_xor(byte, np.left_shift(np.int8(1), pos))\n",
    "\n",
    "\n",
    "# Tuple of suffixes used to identify weight parameters in state dict\n",
    "WEIGHT_SUFFIXES = (\".weight\", \"._packed_params._packed_params\")\n",
    "\n",
    "\n",
    "def randlayer(sd: Dict[str, Any]) -> torch.Tensor:\n",
    "    \"\"\"Randomly selects a layer from model state dictionary.\n",
    "\n",
    "    Args:\n",
    "        sd: Model state dictionary\n",
    "\n",
    "    Returns:\n",
    "        Key of randomly selected layer\n",
    "    \"\"\"\n",
    "    layers = [k for k in sd.keys() if k.endswith(WEIGHT_SUFFIXES)]\n",
    "    return random.choice(layers)\n",
    "\n",
    "\n",
    "def clean_layer(layer: str) -> str:\n",
    "    \"\"\"Removes weight-related suffixes from layer name.\n",
    "\n",
    "    Args:\n",
    "        layer: Full layer name with suffix\n",
    "\n",
    "    Returns:\n",
    "        Clean layer name without suffix\n",
    "    \"\"\"\n",
    "    for suffix in WEIGHT_SUFFIXES:\n",
    "        layer = layer.removesuffix(suffix)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def to_tensor(param) -> torch.Tensor:\n",
    "    \"\"\"Converts parameter to tensor if not already.\n",
    "\n",
    "    Args:\n",
    "        param: Model parameter (tensor or tuple)\n",
    "\n",
    "    Returns:\n",
    "        Parameter as tensor\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If parameter type is not supported\n",
    "    \"\"\"\n",
    "    if isinstance(param, torch.Tensor):\n",
    "        return param\n",
    "    elif isinstance(param, tuple) and len(param) > 0:\n",
    "        return param[0]\n",
    "    raise ValueError(f\"Unsupported parameter type: {type(param)}\")\n",
    "\n",
    "\n",
    "def randidx(tensor: torch.Tensor) -> Tuple[int, ...]:\n",
    "    \"\"\"Generates random indices for each dimension of tensor.\n",
    "\n",
    "    Args:\n",
    "        tensor: Input tensor\n",
    "\n",
    "    Returns:\n",
    "        Tuple of random indices matching tensor dimensions\n",
    "    \"\"\"\n",
    "    return tuple(random.randint(0, s - 1) for s in tensor.shape)\n",
    "\n",
    "\n",
    "def randbitpos() -> int:\n",
    "    \"\"\"Generates random bit position (0-7) for 8-bit integer.\n",
    "\n",
    "    Returns:\n",
    "        Random integer between 0 and 7\n",
    "    \"\"\"\n",
    "    return random.randint(0, 7)\n",
    "\n",
    "\n",
    "def dequant_int8(val: np.int8, scale: float, zero_point: int) -> float:\n",
    "    \"\"\"Dequantizes 8-bit integer to floating point value.\n",
    "\n",
    "    Args:\n",
    "        val: Quantized 8-bit value\n",
    "        scale: Quantization scale factor\n",
    "        zero_point: Quantization zero point\n",
    "\n",
    "    Returns:\n",
    "        Dequantized floating point value\n",
    "    \"\"\"\n",
    "    return float(val - zero_point) * scale\n",
    "\n",
    "\n",
    "def quant_to_int8(tensor: torch.Tensor) -> np.int8:\n",
    "    \"\"\"Converts quantized tensor to 8-bit integer representation.\n",
    "\n",
    "    Args:\n",
    "        tensor: Quantized input tensor\n",
    "\n",
    "    Returns:\n",
    "        NumPy array of 8-bit integers\n",
    "    \"\"\"\n",
    "    return tensor.int_repr().numpy().astype(np.int8)\n",
    "\n",
    "\n",
    "def int8_to_quant(input: np.int8, scale: float, zero_point: int) -> torch.Tensor:\n",
    "    \"\"\"Converts 8-bit integer to quantized tensor.\n",
    "\n",
    "    Args:\n",
    "        input: 8-bit integer input\n",
    "        scale: Quantization scale factor\n",
    "        zero_point: Quantization zero point\n",
    "\n",
    "    Returns:\n",
    "        Quantized tensor\n",
    "    \"\"\"\n",
    "    return quantize_per_tensor(\n",
    "        torch.tensor(dequant_int8(input, scale, zero_point), dtype=torch.float32),\n",
    "        scale,\n",
    "        zero_point,\n",
    "        torch.qint8,\n",
    "    )\n",
    "\n",
    "\n",
    "def infer(input: torch.Tensor, model: nn.Module) -> torch.Tensor:\n",
    "    \"\"\"Performs inference using quantized model.\n",
    "\n",
    "    Args:\n",
    "        input: Input tensor\n",
    "        model: Neural network model\n",
    "\n",
    "    Returns:\n",
    "        Model prediction (argmax of output)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        return torch.argmax(model(input), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a DataLoader for test dataset with specified batch size and number of worker threads for parallel data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_loader = DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs fault injection testing on a quantized neural network by iterating through test data, randomly selecting and flipping bits in model parameters, and recording the impact on model outputs. For each input image, it creates a copy of the model's state, randomly selects a layer and parameter, flips a random bit in that parameter, runs inference with the modified model, and stores the results (including layer information, bit positions, original and flipped parameter values, and model outputs) in a DataFrame that's ultimately saved to a CSV file. After each test, it restores the model to its original state before proceeding to the next input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "NUM_EXPERIMENTS = 10\n",
    "\n",
    "# Initialize empty results list and get original model state\n",
    "results_rand = []\n",
    "orig_sd = flenet.state_dict()\n",
    "\n",
    "for _ in range(NUM_EXPERIMENTS):\n",
    "    # Iterate through test data batches\n",
    "    for inputs, targets in exp_loader:\n",
    "        # Process each input image and target\n",
    "        for input, target in zip(inputs, targets):\n",
    "            input = input.unsqueeze(0)  # Add batch dimension\n",
    "            output = infer(input, flenet)  # Get original model prediction\n",
    "\n",
    "            sd = copy.deepcopy(orig_sd)  # Create copy of model state\n",
    "\n",
    "            # Randomly select layer and parameter to modify\n",
    "            layer = randlayer(sd)\n",
    "            params = to_tensor(sd[layer])\n",
    "            idx = randidx(params)  # Get random parameter index\n",
    "            param = params[idx]  # Get parameter at index\n",
    "\n",
    "            orig_param = quant_to_int8(param)  # Convert to 8-bit int\n",
    "\n",
    "            # Select random bit and get original value\n",
    "            bit_pos = randbitpos()\n",
    "            orig_bit = get_bit(orig_param, bit_pos)\n",
    "            flipped_bit = 1 if orig_bit == 0 else 0\n",
    "\n",
    "            # Create parameter with flipped bit\n",
    "            flipped_param = flip_bit(orig_param, bit_pos)\n",
    "\n",
    "            # Convert back to quantized tensor and update model\n",
    "            params[idx] = int8_to_quant(\n",
    "                flipped_param, param.q_scale(), param.q_zero_point()\n",
    "            )\n",
    "\n",
    "            flenet.load_state_dict(sd)  # Load modified state\n",
    "\n",
    "            flip_output = infer(input, flenet)  # Get prediction with flipped bit\n",
    "\n",
    "            # Store results of this test\n",
    "            results_rand.append(\n",
    "                {\n",
    "                    \"layer\": clean_layer(layer),\n",
    "                    \"bit_position\": bit_pos,\n",
    "                    \"original_bit\": orig_bit,\n",
    "                    \"flipped_bit\": flipped_bit,\n",
    "                    \"original_param\": orig_param,\n",
    "                    \"flipped_param\": flipped_param,\n",
    "                    \"original_output\": output.item(),\n",
    "                    \"flipped_output\": flip_output.item(),\n",
    "                    \"target_output\": target.item(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            flenet.load_state_dict(orig_sd)  # Restore original state\n",
    "\n",
    "# Convert results to DataFrame and save\n",
    "df_rand = pd.DataFrame(results_rand)\n",
    "df_rand.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 4 saved as 'table_4.csv'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>bit_position</th>\n",
       "      <th>samples</th>\n",
       "      <th>errors</th>\n",
       "      <th>error_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1</td>\n",
       "      <td>0</td>\n",
       "      <td>2505</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c1</td>\n",
       "      <td>1</td>\n",
       "      <td>2617</td>\n",
       "      <td>7</td>\n",
       "      <td>0.002675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1</td>\n",
       "      <td>2</td>\n",
       "      <td>2578</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c1</td>\n",
       "      <td>3</td>\n",
       "      <td>2505</td>\n",
       "      <td>12</td>\n",
       "      <td>0.004790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1</td>\n",
       "      <td>4</td>\n",
       "      <td>2452</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>2499</td>\n",
       "      <td>13</td>\n",
       "      <td>0.005202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c1</td>\n",
       "      <td>6</td>\n",
       "      <td>2475</td>\n",
       "      <td>17</td>\n",
       "      <td>0.006869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c1</td>\n",
       "      <td>7</td>\n",
       "      <td>2505</td>\n",
       "      <td>21</td>\n",
       "      <td>0.008383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c3</td>\n",
       "      <td>0</td>\n",
       "      <td>2540</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c3</td>\n",
       "      <td>1</td>\n",
       "      <td>2495</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c3</td>\n",
       "      <td>2</td>\n",
       "      <td>2528</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c3</td>\n",
       "      <td>3</td>\n",
       "      <td>2435</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>c3</td>\n",
       "      <td>4</td>\n",
       "      <td>2496</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>c3</td>\n",
       "      <td>5</td>\n",
       "      <td>2451</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>c3</td>\n",
       "      <td>6</td>\n",
       "      <td>2504</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>c3</td>\n",
       "      <td>7</td>\n",
       "      <td>2490</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>f5</td>\n",
       "      <td>0</td>\n",
       "      <td>2462</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>f5</td>\n",
       "      <td>1</td>\n",
       "      <td>2457</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>f5</td>\n",
       "      <td>2</td>\n",
       "      <td>2400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>f5</td>\n",
       "      <td>3</td>\n",
       "      <td>2534</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>f5</td>\n",
       "      <td>4</td>\n",
       "      <td>2555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>f5</td>\n",
       "      <td>5</td>\n",
       "      <td>2529</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>f5</td>\n",
       "      <td>6</td>\n",
       "      <td>2525</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>f5</td>\n",
       "      <td>7</td>\n",
       "      <td>2465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>f6</td>\n",
       "      <td>0</td>\n",
       "      <td>2420</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>f6</td>\n",
       "      <td>1</td>\n",
       "      <td>2563</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>f6</td>\n",
       "      <td>2</td>\n",
       "      <td>2550</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>f6</td>\n",
       "      <td>3</td>\n",
       "      <td>2498</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>f6</td>\n",
       "      <td>4</td>\n",
       "      <td>2471</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>f6</td>\n",
       "      <td>5</td>\n",
       "      <td>2636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>f6</td>\n",
       "      <td>6</td>\n",
       "      <td>2506</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>f6</td>\n",
       "      <td>7</td>\n",
       "      <td>2529</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>f7</td>\n",
       "      <td>0</td>\n",
       "      <td>2483</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>f7</td>\n",
       "      <td>1</td>\n",
       "      <td>2454</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>f7</td>\n",
       "      <td>2</td>\n",
       "      <td>2566</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>f7</td>\n",
       "      <td>3</td>\n",
       "      <td>2403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>f7</td>\n",
       "      <td>4</td>\n",
       "      <td>2518</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>f7</td>\n",
       "      <td>5</td>\n",
       "      <td>2502</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>f7</td>\n",
       "      <td>6</td>\n",
       "      <td>2425</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>f7</td>\n",
       "      <td>7</td>\n",
       "      <td>2474</td>\n",
       "      <td>21</td>\n",
       "      <td>0.008488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer  bit_position  samples  errors  error_ratio\n",
       "0     c1             0     2505       4     0.001597\n",
       "1     c1             1     2617       7     0.002675\n",
       "2     c1             2     2578       5     0.001939\n",
       "3     c1             3     2505      12     0.004790\n",
       "4     c1             4     2452       8     0.003263\n",
       "5     c1             5     2499      13     0.005202\n",
       "6     c1             6     2475      17     0.006869\n",
       "7     c1             7     2505      21     0.008383\n",
       "8     c3             0     2540       0     0.000000\n",
       "9     c3             1     2495       0     0.000000\n",
       "10    c3             2     2528       0     0.000000\n",
       "11    c3             3     2435       1     0.000411\n",
       "12    c3             4     2496       0     0.000000\n",
       "13    c3             5     2451       1     0.000408\n",
       "14    c3             6     2504       1     0.000399\n",
       "15    c3             7     2490       5     0.002008\n",
       "16    f5             0     2462       0     0.000000\n",
       "17    f5             1     2457       0     0.000000\n",
       "18    f5             2     2400       0     0.000000\n",
       "19    f5             3     2534       0     0.000000\n",
       "20    f5             4     2555       0     0.000000\n",
       "21    f5             5     2529       0     0.000000\n",
       "22    f5             6     2525       0     0.000000\n",
       "23    f5             7     2465       1     0.000406\n",
       "24    f6             0     2420       0     0.000000\n",
       "25    f6             1     2563       0     0.000000\n",
       "26    f6             2     2550       0     0.000000\n",
       "27    f6             3     2498       0     0.000000\n",
       "28    f6             4     2471       0     0.000000\n",
       "29    f6             5     2636       0     0.000000\n",
       "30    f6             6     2506       0     0.000000\n",
       "31    f6             7     2529       0     0.000000\n",
       "32    f7             0     2483       0     0.000000\n",
       "33    f7             1     2454       0     0.000000\n",
       "34    f7             2     2566       0     0.000000\n",
       "35    f7             3     2403       0     0.000000\n",
       "36    f7             4     2518       0     0.000000\n",
       "37    f7             5     2502       2     0.000799\n",
       "38    f7             6     2425       2     0.000825\n",
       "39    f7             7     2474      21     0.008488"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the fault injection results\n",
    "df_rand = pd.read_csv(\"results.csv\")\n",
    "\n",
    "# Group by layer and bit position, and calculate samples, errors, and error ratio\n",
    "table_4 = (\n",
    "    df_rand.groupby([\"layer\", \"bit_position\"])\n",
    "    .agg(\n",
    "        samples=(\"original_output\", \"count\"),  # Total bit flips (Samples)\n",
    "        errors=(\n",
    "            \"original_output\",\n",
    "            lambda x: (x != df_rand.loc[x.index, \"flipped_output\"]).sum(),\n",
    "        ),  # Total Errors\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate Error Ratio\n",
    "table_4[\"error_ratio\"] = table_4[\"errors\"] / table_4[\"samples\"]\n",
    "\n",
    "# Sort the table for better readability\n",
    "table_4 = table_4.sort_values(by=[\"layer\", \"bit_position\"])\n",
    "\n",
    "# Save or display the results\n",
    "table_4.to_csv(\"table_4.csv\", index=False)\n",
    "print(\"Table 4 saved as 'table_4.csv'.\")\n",
    "display(table_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line filters the DataFrame to show only cases where flipping a bit changed the model's output (where original and flipped predictions differ), creating a subset of errors caused by bit flips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bit position impact table saved as 'bit_position_impact.csv'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bit_position</th>\n",
       "      <th>samples</th>\n",
       "      <th>errors</th>\n",
       "      <th>error_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12410</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12586</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12622</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12375</td>\n",
       "      <td>13</td>\n",
       "      <td>0.001051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12492</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>12617</td>\n",
       "      <td>16</td>\n",
       "      <td>0.001268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>12435</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>12463</td>\n",
       "      <td>48</td>\n",
       "      <td>0.003851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bit_position  samples  errors  error_ratio\n",
       "0             0    12410       4     0.000322\n",
       "1             1    12586       7     0.000556\n",
       "2             2    12622       5     0.000396\n",
       "3             3    12375      13     0.001051\n",
       "4             4    12492       8     0.000640\n",
       "5             5    12617      16     0.001268\n",
       "6             6    12435      20     0.001608\n",
       "7             7    12463      48     0.003851"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Generate table for the impact of bit position across all layers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the fault injection results\n",
    "df_rand = pd.read_csv(\"results.csv\")\n",
    "\n",
    "# Group by bit position and calculate samples, errors, and error ratio\n",
    "bit_position_impact = (\n",
    "    df_rand.groupby(\"bit_position\")\n",
    "    .agg(\n",
    "        samples=(\"original_output\", \"count\"),  # Total bit flips for each bit position\n",
    "        errors=(\n",
    "            \"original_output\",\n",
    "            lambda x: (x != df_rand.loc[x.index, \"flipped_output\"]).sum(),\n",
    "        ),  # Total errors for each bit position\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate error ratio\n",
    "bit_position_impact[\"error_ratio\"] = bit_position_impact[\"errors\"] / bit_position_impact[\"samples\"]\n",
    "\n",
    "# Sort the table for readability (ascending order of bit position)\n",
    "bit_position_impact = bit_position_impact.sort_values(by=\"bit_position\")\n",
    "\n",
    "# Save or display the results\n",
    "bit_position_impact.to_csv(\"bit_position_impact.csv\", index=False)\n",
    "print(\"Bit position impact table saved as 'bit_position_impact.csv'.\")\n",
    "display(bit_position_impact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer impact table saved as 'layer_impact.csv'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>samples</th>\n",
       "      <th>errors</th>\n",
       "      <th>error_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1</td>\n",
       "      <td>20136</td>\n",
       "      <td>87</td>\n",
       "      <td>0.004321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c3</td>\n",
       "      <td>19939</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f5</td>\n",
       "      <td>19927</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f6</td>\n",
       "      <td>20173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f7</td>\n",
       "      <td>19825</td>\n",
       "      <td>25</td>\n",
       "      <td>0.001261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  layer  samples  errors  error_ratio\n",
       "0    c1    20136      87     0.004321\n",
       "1    c3    19939       8     0.000401\n",
       "2    f5    19927       1     0.000050\n",
       "3    f6    20173       0     0.000000\n",
       "4    f7    19825      25     0.001261"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Generate table for the impact of layers across all bit positions\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the fault injection results\n",
    "df_rand = pd.read_csv(\"results.csv\")\n",
    "\n",
    "# Group by layer and calculate samples, errors, and error ratio\n",
    "layer_impact = (\n",
    "    df_rand.groupby(\"layer\")\n",
    "    .agg(\n",
    "        samples=(\"original_output\", \"count\"),  # Total bit flips for each layer\n",
    "        errors=(\n",
    "            \"original_output\",\n",
    "            lambda x: (x != df_rand.loc[x.index, \"flipped_output\"]).sum(),\n",
    "        ),  # Total errors for each layer\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate error ratio\n",
    "layer_impact[\"error_ratio\"] = layer_impact[\"errors\"] / layer_impact[\"samples\"]\n",
    "\n",
    "# Sort the table for readability (ascending order of layers)\n",
    "layer_impact = layer_impact.sort_values(by=\"layer\")\n",
    "\n",
    "# Save or display the results\n",
    "layer_impact.to_csv(\"layer_impact.csv\", index=False)\n",
    "print(\"Layer impact table saved as 'layer_impact.csv'.\")\n",
    "display(layer_impact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>bit_position</th>\n",
       "      <th>original_bit</th>\n",
       "      <th>flipped_bit</th>\n",
       "      <th>original_param</th>\n",
       "      <th>flipped_param</th>\n",
       "      <th>original_output</th>\n",
       "      <th>flipped_output</th>\n",
       "      <th>target_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>c1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>90</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>c1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-45</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>c1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>-92</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>f7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>c1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>-68</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95068</th>\n",
       "      <td>c1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>127</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96091</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-97</td>\n",
       "      <td>-65</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96487</th>\n",
       "      <td>f7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99530</th>\n",
       "      <td>c1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-72</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99629</th>\n",
       "      <td>c1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-47</td>\n",
       "      <td>-111</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      layer  bit_position  original_bit  flipped_bit original_param  \\\n",
       "448      c1             6             0            1             26   \n",
       "583      c1             7             1            0            -45   \n",
       "1217     c1             7             0            1             36   \n",
       "2447     f7             5             0            1              1   \n",
       "2927     c1             7             0            1             60   \n",
       "...     ...           ...           ...          ...            ...   \n",
       "95068    c1             7             1            0             -1   \n",
       "96091    c1             5             0            1            -97   \n",
       "96487    f7             5             0            1              1   \n",
       "99530    c1             6             1            0             -8   \n",
       "99629    c1             6             1            0            -47   \n",
       "\n",
       "       flipped_param  original_output  flipped_output  target_output  \n",
       "448               90                9               8              9  \n",
       "583               83                2               7              2  \n",
       "1217             -92                1               9              9  \n",
       "2447              33                9               4              4  \n",
       "2927             -68                7               2              3  \n",
       "...              ...              ...             ...            ...  \n",
       "95068            127                4               9              4  \n",
       "96091            -65                9               5              9  \n",
       "96487             33                9               4              9  \n",
       "99530            -72                8               9              9  \n",
       "99629           -111                3               8              8  \n",
       "\n",
       "[121 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_errors_df = df_rand[df_rand[\"original_output\"] != df_rand[\"flipped_output\"]]\n",
    "\n",
    "rand_errors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4],\n",
       " [Text(0, 0, 'c1'),\n",
       "  Text(1, 0, 'c3'),\n",
       "  Text(2, 0, 'f5'),\n",
       "  Text(3, 0, 'f6'),\n",
       "  Text(4, 0, 'f7')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Layer sensitivity analysis\n",
    "layer_stats = (\n",
    "    df_rand.groupby(\"layer\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"flipped_output\": lambda x: (\n",
    "                x != x.shift()\n",
    "            ).sum(),  # Count changes in output\n",
    "            \"original_output\": \"count\",  # Total flips per layer\n",
    "        }\n",
    "    )\n",
    "    .rename(columns={\"flipped_output\": \"errors\", \"original_output\": \"total\"})\n",
    ")\n",
    "\n",
    "layer_stats[\"error_rate\"] = layer_stats[\"errors\"] / layer_stats[\"total\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(layer_stats.index, layer_stats[\"error_rate\"])\n",
    "plt.title(\"Layer Sensitivity to Fault Injections\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2115/3182270301.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  bit_stats = df_rand.groupby(\"bit_position\").apply(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bit position impact\n",
    "bit_stats = df_rand.groupby(\"bit_position\").apply(\n",
    "   lambda x: (x[\"original_output\"] != x[\"flipped_output\"]).mean()\n",
    ").reset_index(name=\"error_rate\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(bit_stats[\"bit_position\"], bit_stats[\"error_rate\"])\n",
    "plt.title(\"Bit Position Impact\")\n",
    "plt.xlabel(\"Bit Position\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2115/3717712112.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: (x[\"original_output\"] != x[\"flipped_output\"]).mean())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAIQCAYAAAB671NwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDkUlEQVR4nO3dfVhUdf7/8dcgwigF5E8BxyUhbxLTxAVF+HpXsmLSbpSVkCUayeqmaWSGN4G6FmVZ5mqR1YZ5U2a7y5YVRWjZJouKWuJqWatptYO6BCglKDO/P7o82wR6wMBBez6uay6cz3mfc97n4DW9PH3OGYvT6XQKAAAAwBl5uLsBAAAAoKUjNAMAAAAmCM0AAACACUIzAAAAYILQDAAAAJggNAMAAAAmCM0AAACACUIzAAAAYILQDAAAAJggNAO4KFksFs2dO7dZ93HgwAFZLBbl5OQYY3PnzpXFYmnW/Zp5//33ZbFY9P7777u1jx9riT0BQGMQmgFcEHJycmSxWFxeAQEBuuaaa/T222+brr9582bNnTtX5eXlDdrfuHHj6uzv9CsvL+9nHk3DnQ7mp1+tW7dW+/btFRMTo1mzZungwYPnrZeGePrpp13+EdESDB06VL169XJ3G03i4YcfVm5urrvbAH6RPN3dAAA0xvz58xUaGiqn06nS0lLl5ORo5MiReuONN3T99dcbdd9//708Pf/3Ebd582bNmzdP48aNk7+/f4P25e3treeff77OeJ8+fc64zpw5c5Sent7wA2qgpKQkjRw5Ug6HQ99++622bt2qxYsX66mnntILL7ygxMREo3bw4MH6/vvv5eXl1eR9mHn66afVvn17jRs3zmXcnT1dTB5++GHdfPPNSkhIcHcrwC8OoRnABeW6665TZGSk8T4lJUWBgYF6+eWXXUKz1Wr92fvy9PTU7bff3uh1fhzWm8qvf/3rOr18+eWXGj58uJKTkxUWFmaEeQ8PjwYd/3fffae2bds2ea/1aWhPANBSMT0DwAXN399fbdq0qRNUfzynee7cubr//vslSaGhocZUhwMHDjR5P/XNabZYLJo8ebJWr16tK6+8UlarVREREdq0adPP2lfnzp2Vk5OjmpoaLVy40Bivb/7w6SkKxcXFGjx4sNq2batZs2ZJkqqrq5WZmamuXbvK29tbwcHBmjFjhqqrq+vsc9WqVerfv7/atm2ryy67TIMHD9a7774rSQoJCdHu3bv1wQcfGOd46NChZ+xJktatW6eIiAi1adNG7du31+23366vv/7apWbcuHG65JJL9PXXXyshIUGXXHKJOnTooOnTp6u2tvaczt3p38m6devUs2dPtWnTRtHR0dq1a5ck6dlnn1XXrl1ltVo1dOjQOn9Xfnw+Y2Ji1KZNG4WGhio7O9ulrqamRhkZGYqIiJCfn598fHw0aNAgbdy4sU5PDodDTz31lHr37i2r1aoOHTpoxIgR2rZtm9FzVVWVVqxYYZzfn17RB9B8uNIM4IJSUVGho0ePyul06vDhw/rTn/6k48ePn/WK8E033aTPPvtML7/8sp588km1b99ektShQwfT/R09etTlfevWreXn59fovj/44AOtXbtW99xzj7y9vfX0009rxIgR2rJly8+abxsdHa0uXbooPz/ftPa///2vrrvuOiUmJur2229XYGCgHA6Hfve73+kf//iHUlNTFRYWpl27dunJJ5/UZ5995jJ/dt68eZo7d65iYmI0f/58eXl5qaioSBs2bNDw4cO1ePFiTZkyRZdccolmz54tSQoMDDxjPzk5ORo/frz69eunrKwslZaW6qmnntJHH32kHTt2uEyjqa2tVVxcnKKiovT444/rvffe06JFi9SlSxdNmjTpnM7dhx9+qNdff1133323JCkrK0vXX3+9ZsyYoaefflp/+MMf9O2332rhwoW68847tWHDBpf1v/32W40cOVK33nqrkpKS9Oqrr2rSpEny8vLSnXfeKUmqrKzU888/r6SkJE2YMEHHjh3TCy+8oLi4OG3ZskXh4eHG9lJSUpSTk6PrrrtOd911l06dOqUPP/xQ//znPxUZGamVK1fqrrvuUv/+/ZWamipJ6tKlyzkdO4Bz4ASAC8CLL77olFTn5e3t7czJyalTL8mZmZlpvH/ssceckpz79+9v0P6Sk5Pr3d+QIUOMmv379zslOV988UVjLDMz0/nTj9bT627bts0Y+/LLL51Wq9V54403nrWP0/t47LHHzlhzww03OCU5KyoqnE6n07lx40anJOfGjRuNmiFDhjglObOzs13WXblypdPDw8P54YcfuoxnZ2c7JTk/+ugjp9PpdO7bt8/p4eHhvPHGG521tbUutQ6Hw/jzVVdd5XKOTvtpTzU1Nc6AgABnr169nN9//71Rt379eqckZ0ZGhjF2+ncxf/58l2327dvXGRERccbz8uNjv+qqq1zGTv/d+fHfh2effdYpyRkUFOSsrKw0xmfOnFnn787p87lo0SJjrLq62hkeHu4MCAhw1tTUOJ1Op/PUqVPO6upql31/++23zsDAQOedd95pjG3YsMEpyXnPPffU6f/H59fHx8eZnJxseswAmh5XmgFcUJYtW6bu3btLkkpLS7Vq1SrddddduvTSS3XTTTc16b6sVqveeOMNl7HLLrvsnLYVHR2tiIgI4/3ll1+uG264QW+88YZqa2vVqlWrc+7zkksukSQdO3ZMvr6+Z6zz9vbW+PHjXcbWrVunsLAw9ejRw+Wq+rXXXitJ2rhxo2JiYpSbmyuHw6GMjAx5eLjO7DuXR+xt27ZNhw8f1ty5c13mOsfHx6tHjx568803NW/ePJd1Jk6c6PJ+0KBBWrlyZaP3fdqwYcMUEhJivI+KipIkjRo1Spdeemmd8X//+98u9Z6envr9739vvPfy8tLvf/97TZo0ScXFxRowYIBatWpl/G4dDofKy8vlcDgUGRmp7du3G+v+5S9/kcViUWZmZp0+3f0IQwA/IDQDuKD079/f5UbApKQk9e3bV5MnT9b111/fpE9naNWqlWJjY5tkW926dasz1r17d3333Xc6cuSIgoKCznnbx48flySXoFefTp061Tk/+/bt0549e844VeXw4cOSpC+++EIeHh7q2bPnOff5Y19++aUk6corr6yzrEePHvrHP/7hMnZ6ju+PXXbZZfr222/PuYfLL7/c5f3paTfBwcH1jv90XzabTT4+Pi5jp/9Bd+DAAQ0YMECStGLFCi1atEh79+7VyZMnjdrQ0FDjz1988YVsNpvatWt3zscDoHkRmgFc0Dw8PHTNNdfoqaee0r59+3TVVVe5u6XzrqSkRAEBAWe9yixJbdq0qTPmcDjUu3dvPfHEE/Wu89MA6S4/50p8Y7d5pnGn09nofaxatUrjxo1TQkKC7r//fgUEBKhVq1bKysrSF1980ejtAXAfQjOAC96pU6ck/e+Ka33c/b+49+3bV2fss88+U9u2bRt0Q+KZFBYW6osvvmj0o/FO69Kliz7++GMNGzbsrOeoS5cucjgc+te//uVy89pPNfQ8d+7cWZL06aefGlNBTvv000+N5S3ZN998o6qqKperzZ999pkkGdM4XnvtNV1xxRX661//6nJufjoNo0uXLnrnnXdUVlZ21qvN7v57DPyS8cg5ABe0kydP6t1335WXl5fCwsLOWHc62DT0GwGbWmFhocsc1kOHDunvf/+7hg8ffs5XUb/88kuNGzdOXl5exiP1GuvWW2/V119/reeee67Osu+//15VVVWSpISEBHl4eGj+/PlyOBwudT++Auvj49OgcxwZGamAgABlZ2e7PNru7bff1p49exQfH39Ox3M+nTp1Ss8++6zxvqamRs8++6w6dOhgzF8//bv98TkqKipSYWGhy7ZGjRolp9NZZx73T9dt6PkF0PS40gzggvL2229r7969kn6Yb7tmzRrt27dP6enpZ52ecDrEzJ49W4mJiWrdurV++9vf1pmT2lx69eqluLg4l0fOSao3JNVn+/btWrVqlXEz2datW42bx1auXKmrr776nPq644479Oqrr2rixInauHGj/u///k+1tbXau3evXn31Vb3zzjuKjIxU165dNXv2bP3xj3/UoEGDdNNNN8nb21tbt26VzWZTVlaWpB/O8zPPPKMFCxaoa9euCggIqHMlWfrh0X2PPvqoxo8fryFDhigpKcl45FxISIjuvffeczqe88lms+nRRx/VgQMH1L17d61du1Y7d+7U8uXL1bp1a0nS9ddfr7/+9a+68cYbFR8fr/379ys7O1s9e/Z0+T8j11xzje644w4tWbJE+/bt04gRI+RwOPThhx/qmmuu0eTJkyX9cH7fe+89PfHEE7LZbAoNDTVuVATQvAjNAC4oGRkZxp+tVqt69OihZ555xuUpBvXp16+f/vjHPyo7O1t5eXlyOBzav3//eQvNQ4YMUXR0tObNm6eDBw+qZ8+eysnJaXDYffnll/Xyyy/L09NTvr6+6tatm6ZNm6aJEyfWuaGtMTw8PJSbm6snn3xSL730kv72t7+pbdu2uuKKKzR16lTjxjbpf19h/qc//UmzZ89W27ZtdfXVV+uOO+4wajIyMvTll19q4cKFOnbsmIYMGVJvaJZ++NKStm3b6pFHHtEDDzwgHx8f3XjjjXr00Ucb/FXn7nTZZZdpxYoVmjJlip577jkFBgZq6dKlmjBhglEzbtw42e12Pfvss3rnnXfUs2dPrVq1SuvWravzRS8vvviirr76ar3wwgu6//775efnp8jISMXExBg1TzzxhFJTUzVnzhx9//33Sk5OJjQD54nFeS53NgAAGsxisejuu+/W0qVL3d0KmsjQoUN19OhRlZSUuLsVAOcJc5oBAAAAE4RmAAAAwAShGQAAADDBnGYAAADABFeaAQAAABOEZgAAAMAEz2luRg6HQ998840uvfRSvvoUAACgBXI6nTp27JhsNps8PM58PZnQ3Iy++eYbBQcHu7sNAAAAmDh06JB+9atfnXE5obkZXXrppZJ++CWc7et9AQAA4B6VlZUKDg42ctuZEJqb0ekpGb6+voRmAACAFsxsKi03AgIAAAAmCM0AAACACUIzAAAAYILQDAAAAJggNAMAAAAmCM0AAACACUIzAAAAYILQDAAAAJggNAMAAAAmCM0AAACACUIzAAAAYILQDAAAAJggNAMAAAAmCM0AAACACUIzAAAAYILQDAAAAJggNAMAAAAmCM0AAACACUIzAAAAYMLT3Q0AANBQIelvursFAM3swCPx7m6hXlxpBgAAAEy4PTQvW7ZMISEhslqtioqK0pYtW85av27dOvXo0UNWq1W9e/fWW2+95bLc6XQqIyNDHTt2VJs2bRQbG6t9+/a51Dz00EOKiYlR27Zt5e/vX2cfH3/8sZKSkhQcHKw2bdooLCxMTz311M8+VgAAAFyY3Bqa165dq7S0NGVmZmr79u3q06eP4uLidPjw4XrrN2/erKSkJKWkpGjHjh1KSEhQQkKCSkpKjJqFCxdqyZIlys7OVlFRkXx8fBQXF6cTJ04YNTU1Nbrllls0adKkevdTXFysgIAArVq1Srt379bs2bM1c+ZMLV26tGlPAAAAAC4IFqfT6XTXzqOiotSvXz8jjDocDgUHB2vKlClKT0+vUz969GhVVVVp/fr1xtiAAQMUHh6u7OxsOZ1O2Ww23XfffZo+fbokqaKiQoGBgcrJyVFiYqLL9nJycjRt2jSVl5eb9nr33Xdrz5492rBhQ4OPr7KyUn5+fqqoqJCvr2+D1wMA1I85zcDF73zPaW5oXnPbjYA1NTUqLi7WzJkzjTEPDw/FxsaqsLCw3nUKCwuVlpbmMhYXF6fc3FxJ0v79+2W32xUbG2ss9/PzU1RUlAoLC+uE5saoqKhQu3btzlpTXV2t6upq431lZeU57+9c8R8U4OLXUm+SAYCLmdumZxw9elS1tbUKDAx0GQ8MDJTdbq93Hbvdftb60z8bs82G2Lx5s9auXavU1NSz1mVlZcnPz894BQcHn/M+AQAA0HK4/UbAlq6kpEQ33HCDMjMzNXz48LPWzpw5UxUVFcbr0KFD56lLAAAANCe3heb27durVatWKi0tdRkvLS1VUFBQvesEBQWdtf70z8Zs82z+9a9/adiwYUpNTdWcOXNM6729veXr6+vyAgAAwIXPbaHZy8tLERERKigoMMYcDocKCgoUHR1d7zrR0dEu9ZKUn59v1IeGhiooKMilprKyUkVFRWfc5pns3r1b11xzjZKTk/XQQw81al0AAABcXNz6jYBpaWlKTk5WZGSk+vfvr8WLF6uqqkrjx4+XJI0dO1adOnVSVlaWJGnq1KkaMmSIFi1apPj4eL3yyivatm2bli9fLkmyWCyaNm2aFixYoG7duik0NFQPPvigbDabEhISjP0ePHhQZWVlOnjwoGpra7Vz505JUteuXXXJJZeopKRE1157reLi4pSWlmbMh27VqpU6dOhw/k4QAAAAWgS3hubRo0fryJEjysjIkN1uV3h4uPLy8owb+Q4ePCgPj/9dDI+JidGaNWs0Z84czZo1S926dVNubq569epl1MyYMUNVVVVKTU1VeXm5Bg4cqLy8PFmtVqMmIyNDK1asMN737dtXkrRx40YNHTpUr732mo4cOaJVq1Zp1apVRl3nzp114MCB5jodAAAAaKHc+pzmi507ntPMI+eAi98v+ZFzfMYBF7+W+pxmnp4BAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmHB7aF62bJlCQkJktVoVFRWlLVu2nLV+3bp16tGjh6xWq3r37q233nrLZbnT6VRGRoY6duyoNm3aKDY2Vvv27XOpeeihhxQTE6O2bdvK39+/3v0cPHhQ8fHxatu2rQICAnT//ffr1KlTP+tYAQAAcGFya2heu3at0tLSlJmZqe3bt6tPnz6Ki4vT4cOH663fvHmzkpKSlJKSoh07dighIUEJCQkqKSkxahYuXKglS5YoOztbRUVF8vHxUVxcnE6cOGHU1NTU6JZbbtGkSZPq3U9tba3i4+NVU1OjzZs3a8WKFcrJyVFGRkbTngAAAABcECxOp9Pprp1HRUWpX79+Wrp0qSTJ4XAoODhYU6ZMUXp6ep360aNHq6qqSuvXrzfGBgwYoPDwcGVnZ8vpdMpms+m+++7T9OnTJUkVFRUKDAxUTk6OEhMTXbaXk5OjadOmqby83GX87bff1vXXX69vvvlGgYGBkqTs7Gw98MADOnLkiLy8vBp0fJWVlfLz81NFRYV8fX0bfF5+jpD0N8/LfgC4z4FH4t3dgtvwGQdc/M73Z1xD85rbrjTX1NSouLhYsbGx/2vGw0OxsbEqLCysd53CwkKXekmKi4sz6vfv3y+73e5S4+fnp6ioqDNu80z76d27txGYT++nsrJSu3fvPuN61dXVqqysdHkBAADgwue20Hz06FHV1ta6BFNJCgwMlN1ur3cdu91+1vrTPxuzzcbs58f7qE9WVpb8/PyMV3BwcIP3CQAAgJbL7TcCXkxmzpypiooK43Xo0CF3twQAAIAm4LbQ3L59e7Vq1UqlpaUu46WlpQoKCqp3naCgoLPWn/7ZmG02Zj8/3kd9vL295evr6/ICAADAhc9todnLy0sREREqKCgwxhwOhwoKChQdHV3vOtHR0S71kpSfn2/Uh4aGKigoyKWmsrJSRUVFZ9zmmfaza9cul6d45Ofny9fXVz179mzwdgAAAHBx8HTnztPS0pScnKzIyEj1799fixcvVlVVlcaPHy9JGjt2rDp16qSsrCxJ0tSpUzVkyBAtWrRI8fHxeuWVV7Rt2zYtX75ckmSxWDRt2jQtWLBA3bp1U2hoqB588EHZbDYlJCQY+z148KDKysp08OBB1dbWaufOnZKkrl276pJLLtHw4cPVs2dP3XHHHVq4cKHsdrvmzJmju+++W97e3uf1HAEAAMD93BqaR48erSNHjigjI0N2u13h4eHKy8szbro7ePCgPDz+dzE8JiZGa9as0Zw5czRr1ix169ZNubm56tWrl1EzY8YMVVVVKTU1VeXl5Ro4cKDy8vJktVqNmoyMDK1YscJ437dvX0nSxo0bNXToULVq1Urr16/XpEmTFB0dLR8fHyUnJ2v+/PnNfUoAAADQArn1Oc0XO57TDKA58JxmABczntMMAAAAXKAIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACbcHpqXLVumkJAQWa1WRUVFacuWLWetX7dunXr06CGr1arevXvrrbfeclnudDqVkZGhjh07qk2bNoqNjdW+fftcasrKyjRmzBj5+vrK399fKSkpOn78uEvNO++8owEDBujSSy9Vhw4dNGrUKB04cKBJjhkAAAAXFreG5rVr1yotLU2ZmZnavn27+vTpo7i4OB0+fLje+s2bNyspKUkpKSnasWOHEhISlJCQoJKSEqNm4cKFWrJkibKzs1VUVCQfHx/FxcXpxIkTRs2YMWO0e/du5efna/369dq0aZNSU1ON5fv379cNN9yga6+9Vjt37tQ777yjo0eP6qabbmq+kwEAAIAWy+J0Op3u2nlUVJT69eunpUuXSpIcDoeCg4M1ZcoUpaen16kfPXq0qqqqtH79emNswIABCg8PV3Z2tpxOp2w2m+677z5Nnz5dklRRUaHAwEDl5OQoMTFRe/bsUc+ePbV161ZFRkZKkvLy8jRy5Eh99dVXstlseu2115SUlKTq6mp5ePzw74o33nhDN9xwg6qrq9W6desGHV9lZaX8/PxUUVEhX1/fn3WuGiok/c3zsh8A7nPgkXh3t+A2fMYBF7/z/RnX0LzmtivNNTU1Ki4uVmxs7P+a8fBQbGysCgsL612nsLDQpV6S4uLijPr9+/fLbre71Pj5+SkqKsqoKSwslL+/vxGYJSk2NlYeHh4qKiqSJEVERMjDw0MvvviiamtrVVFRoZUrVyo2NrbBgRkAAAAXD7eF5qNHj6q2tlaBgYEu44GBgbLb7fWuY7fbz1p/+qdZTUBAgMtyT09PtWvXzqgJDQ3Vu+++q1mzZsnb21v+/v766quv9Oqrr571mKqrq1VZWenyAgAAwIXP7TcCtkR2u10TJkxQcnKytm7dqg8++EBeXl66+eabdbbZLFlZWfLz8zNewcHB57FrAAAANBe3heb27durVatWKi0tdRkvLS1VUFBQvesEBQWdtf70T7Oan95oeOrUKZWVlRk1y5Ytk5+fnxYuXKi+fftq8ODBWrVqlQoKCowpHPWZOXOmKioqjNehQ4fMTgMAAAAuAG4LzV5eXoqIiFBBQYEx5nA4VFBQoOjo6HrXiY6OdqmXpPz8fKM+NDRUQUFBLjWVlZUqKioyaqKjo1VeXq7i4mKjZsOGDXI4HIqKipIkfffdd8YNgKe1atXK6PFMvL295evr6/ICAADAhc+t0zPS0tL03HPPacWKFdqzZ48mTZqkqqoqjR8/XpI0duxYzZw506ifOnWq8vLytGjRIu3du1dz587Vtm3bNHnyZEmSxWLRtGnTtGDBAr3++uvatWuXxo4dK5vNpoSEBElSWFiYRowYoQkTJmjLli366KOPNHnyZCUmJspms0mS4uPjtXXrVs2fP1/79u3T9u3bNX78eHXu3Fl9+/Y9vycJAAAAbufpzp2PHj1aR44cUUZGhux2u8LDw5WXl2fcyHfw4EGXK74xMTFas2aN5syZo1mzZqlbt27Kzc1Vr169jJoZM2aoqqpKqampKi8v18CBA5WXlyer1WrUrF69WpMnT9awYcPk4eGhUaNGacmSJcbya6+9VmvWrNHChQu1cOFCtW3bVtHR0crLy1ObNm3Ow5kBAABAS+LW5zRf7HhOM4DmwHOaAVzMeE4zAAAAcIEiNAMAAAAmCM0AAACACUIzAAAAYILQDAAAAJggNAMAAAAmCM0AAACACUIzAAAAYILQDAAAAJggNAMAAAAmCM0AAACACUIzAAAAYILQDAAAAJggNAMAAAAmCM0AAACACUIzAAAAYILQDAAAAJggNAMAAAAmCM0AAACAiXMKzV988YXmzJmjpKQkHT58WJL09ttva/fu3U3aHAAAANASNDo0f/DBB+rdu7eKior017/+VcePH5ckffzxx8rMzGzyBgEAAAB3a3RoTk9P14IFC5Sfny8vLy9j/Nprr9U///nPJm0OAAAAaAkaHZp37dqlG2+8sc54QECAjh492iRNAQAAAC1Jo0Ozv7+//vOf/9QZ37Fjhzp16tQkTQEAAAAtSaNDc2Jioh544AHZ7XZZLBY5HA599NFHmj59usaOHdscPQIAAABu1ejQ/PDDD6tHjx4KDg7W8ePH1bNnTw0ePFgxMTGaM2dOc/QIAAAAuJVnY1fw8vLSc889p4yMDO3atUvHjx9X37591a1bt+boDwAAAHC7Rl9pnj9/vr777jsFBwdr5MiRuvXWW9WtWzd9//33mj9/fnP0CAAAALhVo0PzvHnzjGcz/9h3332nefPmNUlTAAAAQEvS6NDsdDplsVjqjH/88cdq165dkzQFAAAAtCQNntN82WWXyWKxyGKxqHv37i7Buba2VsePH9fEiRObpUkAAADAnRocmhcvXiyn06k777xT8+bNk5+fn7HMy8tLISEhio6ObpYmAQAAAHdqcGhOTk6WJIWGhiomJkatW7dutqYAAACAlqTRj5wbMmSI8ecTJ06opqbGZbmvr+/P7woAAABoQRp9I+B3332nyZMnKyAgQD4+PrrssstcXgAAAMDFptGh+f7779eGDRv0zDPPyNvbW88//7zmzZsnm82ml156qTl6BAAAANyq0dMz3njjDb300ksaOnSoxo8fr0GDBqlr167q3LmzVq9erTFjxjRHnwAAAIDbNPpKc1lZma644gpJP8xfLisrkyQNHDhQmzZtatruAAAAgBag0aH5iiuu0P79+yVJPXr00KuvvirphyvQ/v7+TdocAAAA0BI0OjSPHz9eH3/8sSQpPT1dy5Ytk9Vq1b333qv777+/yRsEAAAA3K3Rc5rvvfde48+xsbHau3eviouL1bVrV1199dVN2hwAAADQEjQ6NP9U586d1blzZ0nSa6+9pptvvvlnNwUAAAC0JI2annHq1CmVlJTos88+cxn/+9//rj59+vDkDAAAAFyUGhyaS0pK1LVrV/Xp00dhYWG66aabVFpaqiFDhujOO+/Uddddpy+++KI5ewUAAADcosHTMx544AF17dpVS5cu1csvv6yXX35Ze/bsUUpKivLy8tSmTZvm7BMAAABwmwaH5q1bt+rdd99VeHi4Bg0apJdfflmzZs3SHXfc0Zz9AQAAAG7X4OkZR48elc1mkyT5+fnJx8dHAwYMaLbGAAAAgJaiwVeaLRaLjh07JqvVKqfTKYvFou+//16VlZUudb6+vk3eJAAAAOBODQ7NTqdT3bt3d3nft29fl/cWi0W1tbVN2yEAAADgZg0OzRs3bmzOPgAAAIAWq8GheciQIc3ZBwAAANBiNerLTQAAAIBfIkIzAAAAYILQDAAAAJggNAMAAAAmGhWaT548KU9PT5WUlDRXPwAAAECL06jQ3Lp1a11++eU8ixkAAAC/KI2enjF79mzNmjVLZWVlzdEPAAAA0OI0+DnNpy1dulSff/65bDabOnfuLB8fH5fl27dvb7LmAAAAgJag0aE5ISGhGdoAAAAAWq5Gh+bMzMzm6AMAAABosRodmk8rLi7Wnj17JElXXXWV+vbt22RNAQAAAC1Jo28EPHz4sK699lr169dP99xzj+655x5FRERo2LBhOnLkSKMbWLZsmUJCQmS1WhUVFaUtW7actX7dunXq0aOHrFarevfurbfeestludPpVEZGhjp27Kg2bdooNjZW+/btc6kpKyvTmDFj5OvrK39/f6WkpOj48eN1tvP444+re/fu8vb2VqdOnfTQQw81+vgAAABw4Wt0aJ4yZYqOHTum3bt3q6ysTGVlZSopKVFlZaXuueeeRm1r7dq1SktLU2ZmprZv364+ffooLi5Ohw8frrd+8+bNSkpKUkpKinbs2KGEhAQlJCS4PDd64cKFWrJkibKzs1VUVCQfHx/FxcXpxIkTRs2YMWO0e/du5efna/369dq0aZNSU1Nd9jV16lQ9//zzevzxx7V37169/vrr6t+/f6OODwAAABcHi9PpdDZmBT8/P7333nvq16+fy/iWLVs0fPhwlZeXN3hbUVFR6tevn5YuXSpJcjgcCg4O1pQpU5Senl6nfvTo0aqqqtL69euNsQEDBig8PFzZ2dlyOp2y2Wy67777NH36dElSRUWFAgMDlZOTo8TERO3Zs0c9e/bU1q1bFRkZKUnKy8vTyJEj9dVXX8lms2nPnj26+uqrVVJSoiuvvLIxp8dFZWWl/Pz8VFFRIV9f33PeTmOEpL95XvYDwH0OPBLv7hbchs844OJ3vj/jGprXGn2l2eFwqHXr1nXGW7duLYfD0eDt1NTUqLi4WLGxsf9rxsNDsbGxKiwsrHedwsJCl3pJiouLM+r3798vu93uUuPn56eoqCijprCwUP7+/kZglqTY2Fh5eHioqKhIkvTGG2/oiiuu0Pr16xUaGqqQkBDdddddps+mrq6uVmVlpcsLAAAAF75Gh+Zrr71WU6dO1TfffGOMff3117r33ns1bNiwBm/n6NGjqq2tVWBgoMt4YGCg7HZ7vevY7faz1p/+aVYTEBDgstzT01Pt2rUzav7973/ryy+/1Lp16/TSSy8pJydHxcXFuvnmm896TFlZWfLz8zNewcHBZ60HAADAhaHRoXnp0qWqrKxUSEiIunTpoi5duig0NFSVlZX605/+1Bw9nncOh0PV1dV66aWXNGjQIA0dOlQvvPCCNm7cqE8//fSM682cOVMVFRXG69ChQ+exawAAADSXRj9yLjg4WNu3b9d7772nvXv3SpLCwsLqTJsw0759e7Vq1UqlpaUu46WlpQoKCqp3naCgoLPWn/5ZWlqqjh07utSEh4cbNT+90fDUqVMqKysz1u/YsaM8PT3VvXt3oyYsLEySdPDgwTPOc/b29pa3t/dZjxsAAAAXnkZdaT558qQ8PT21e/du/eY3v9GUKVM0ZcqURgdmSfLy8lJERIQKCgqMMYfDoYKCAkVHR9e7TnR0tEu9JOXn5xv1oaGhCgoKcqmprKxUUVGRURMdHa3y8nIVFxcbNRs2bJDD4VBUVJQk6f/+7/906tQpffHFF0bNZ599Jknq3Llzo48VAAAAF7ZGXWlu3bq1Lr/8ctXW1jbJztPS0pScnKzIyEj1799fixcvVlVVlcaPHy9JGjt2rDp16qSsrCxJPzwGbsiQIVq0aJHi4+P1yiuvaNu2bVq+fLkkyWKxaNq0aVqwYIG6deum0NBQPfjgg7LZbMbXf4eFhWnEiBGaMGGCsrOzdfLkSU2ePFmJiYmy2WySfrgx8Ne//rXuvPNOLV68WA6HQ3fffbd+85vfuFx9BgAAwC9Do+c0z549W7NmzTJ9kkRDjB49Wo8//rgyMjIUHh6unTt3Ki8vz7iR7+DBg/rPf/5j1MfExGjNmjVavny5+vTpo9dee025ubnq1auXUTNjxgxNmTJFqamp6tevn44fP668vDxZrVajZvXq1erRo4eGDRumkSNHauDAgUbwln54iscbb7yh9u3ba/DgwYqPj1dYWJheeeWVn33MAAAAuPA0+jnNffv21eeff66TJ0+qc+fO8vHxcVm+ffv2Jm3wQsZzmgE0B57TDOBi1lKf09zoGwFPT3MAAAAAfikaFZpPnToli8WiO++8U7/61a+aqycAAACgRWnUnGZPT0899thjOnXqVHP1AwAAALQ45/SNgB988EFz9AIAAAC0SI2e03zdddcpPT1du3btUkRERJ0bAX/3u981WXMAAABAS9Do0PyHP/xBkvTEE0/UWWaxWJrsGc4AAABAS9Ho0OxwOJqjDwAAAKDFavScZgAAAOCXpsGheeTIkaqoqDDeP/LIIyovLzfe//e//1XPnj2btDkAAACgJWhwaH7nnXdUXV1tvH/44Yddvkr71KlT+vTTT5u2OwAAAKAFaHBo/um3bTfy27cBAACACxZzmgEAAAATDQ7NFotFFoulzhgAAABwsWvwI+ecTqfGjRsnb29vSdKJEyc0ceJE48tNfjzfGQAAALiYNDg0Jycnu7y//fbb69SMHTv253cEAAAAtDANDs0vvvhic/YBAAAAtFjcCAgAAACYIDQDAAAAJgjNAAAAgAlCMwAAAGCC0AwAAACYIDQDAAAAJgjNAAAAgAlCMwAAAGCC0AwAAACYIDQDAAAAJgjNAAAAgAlCMwAAAGCC0AwAAACYIDQDAAAAJgjNAAAAgAlCMwAAAGCC0AwAAACYIDQDAAAAJgjNAAAAgAlCMwAAAGCC0AwAAACYIDQDAAAAJgjNAAAAgAlCMwAAAGCC0AwAAACYIDQDAAAAJgjNAAAAgAlCMwAAAGCC0AwAAACYIDQDAAAAJgjNAAAAgAlCMwAAAGCC0AwAAACYIDQDAAAAJgjNAAAAgAlCMwAAAGCC0AwAAACYIDQDAAAAJgjNAAAAgAlCMwAAAGCC0AwAAACYIDQDAAAAJgjNAAAAgAlCMwAAAGCC0AwAAACYaBGhedmyZQoJCZHValVUVJS2bNly1vp169apR48eslqt6t27t9566y2X5U6nUxkZGerYsaPatGmj2NhY7du3z6WmrKxMY8aMka+vr/z9/ZWSkqLjx4/Xu7/PP/9cl156qfz9/X/WcQIAAODC5PbQvHbtWqWlpSkzM1Pbt29Xnz59FBcXp8OHD9dbv3nzZiUlJSklJUU7duxQQkKCEhISVFJSYtQsXLhQS5YsUXZ2toqKiuTj46O4uDidOHHCqBkzZox2796t/Px8rV+/Xps2bVJqamqd/Z08eVJJSUkaNGhQ0x88AAAALggWp9PpdGcDUVFR6tevn5YuXSpJcjgcCg4O1pQpU5Senl6nfvTo0aqqqtL69euNsQEDBig8PFzZ2dlyOp2y2Wy67777NH36dElSRUWFAgMDlZOTo8TERO3Zs0c9e/bU1q1bFRkZKUnKy8vTyJEj9dVXX8lmsxnbfuCBB/TNN99o2LBhmjZtmsrLyxt8bJWVlfLz81NFRYV8fX3P5fQ0Wkj6m+dlPwDc58Aj8e5uwW34jAMufuf7M66hec2tV5prampUXFys2NhYY8zDw0OxsbEqLCysd53CwkKXekmKi4sz6vfv3y+73e5S4+fnp6ioKKOmsLBQ/v7+RmCWpNjYWHl4eKioqMgY27Bhg9atW6dly5b9/IMFAADABcvTnTs/evSoamtrFRgY6DIeGBiovXv31ruO3W6vt95utxvLT4+drSYgIMBluaenp9q1a2fU/Pe//9W4ceO0atWqBl8lrq6uVnV1tfG+srKyQesBAACgZXP7nOaWasKECbrttts0ePDgBq+TlZUlPz8/4xUcHNyMHQIAAOB8cWtobt++vVq1aqXS0lKX8dLSUgUFBdW7TlBQ0FnrT/80q/npjYanTp1SWVmZUbNhwwY9/vjj8vT0lKenp1JSUlRRUSFPT0/9+c9/rre3mTNnqqKiwngdOnSoIacBAAAALZxbQ7OXl5ciIiJUUFBgjDkcDhUUFCg6OrredaKjo13qJSk/P9+oDw0NVVBQkEtNZWWlioqKjJro6GiVl5eruLjYqNmwYYMcDoeioqIk/TDveefOncZr/vz5uvTSS7Vz507deOON9fbm7e0tX19flxcAAAAufG6d0yxJaWlpSk5OVmRkpPr376/FixerqqpK48ePlySNHTtWnTp1UlZWliRp6tSpGjJkiBYtWqT4+Hi98sor2rZtm5YvXy5JslgsmjZtmhYsWKBu3bopNDRUDz74oGw2mxISEiRJYWFhGjFihCZMmKDs7GydPHlSkydPVmJiovHkjLCwMJc+t23bJg8PD/Xq1es8nRkAAAC0FG4PzaNHj9aRI0eUkZEhu92u8PBw5eXlGTfyHTx4UB4e/7sgHhMTozVr1mjOnDmaNWuWunXrptzcXJcwO2PGDFVVVSk1NVXl5eUaOHCg8vLyZLVajZrVq1dr8uTJGjZsmDw8PDRq1CgtWbLk/B04AAAALhhuf07zxYznNANoDjynGcDFjOc0AwAAABcoQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAICJFhGaly1bppCQEFmtVkVFRWnLli1nrV+3bp169Oghq9Wq3r1766233nJZ7nQ6lZGRoY4dO6pNmzaKjY3Vvn37XGrKyso0ZswY+fr6yt/fXykpKTp+/Lix/P3339cNN9ygjh07ysfHR+Hh4Vq9enXTHTQAAAAuGG4PzWvXrlVaWpoyMzO1fft29enTR3FxcTp8+HC99Zs3b1ZSUpJSUlK0Y8cOJSQkKCEhQSUlJUbNwoULtWTJEmVnZ6uoqEg+Pj6Ki4vTiRMnjJoxY8Zo9+7dys/P1/r167Vp0yalpqa67Ofqq6/WX/7yF33yyScaP368xo4dq/Xr1zffyQAAAECLZHE6nU53NhAVFaV+/fpp6dKlkiSHw6Hg4GBNmTJF6enpdepHjx6tqqoql/A6YMAAhYeHKzs7W06nUzabTffdd5+mT58uSaqoqFBgYKBycnKUmJioPXv2qGfPntq6dasiIyMlSXl5eRo5cqS++uor2Wy2enuNj49XYGCg/vznPzfo2CorK+Xn56eKigr5+vo26rycq5D0N8/LfgC4z4FH4t3dgtvwGQdc/M73Z1xD85pbrzTX1NSouLhYsbGxxpiHh4diY2NVWFhY7zqFhYUu9ZIUFxdn1O/fv192u92lxs/PT1FRUUZNYWGh/P39jcAsSbGxsfLw8FBRUdEZ+62oqFC7du0af6AAAAC4oHm6c+dHjx5VbW2tAgMDXcYDAwO1d+/eetex2+311tvtdmP56bGz1QQEBLgs9/T0VLt27Yyan3r11Ve1detWPfvss2c8nurqalVXVxvvKysrz1gLAACAC4fb5zRfCDZu3Kjx48frueee01VXXXXGuqysLPn5+Rmv4ODg89glAAAAmotbQ3P79u3VqlUrlZaWuoyXlpYqKCio3nWCgoLOWn/6p1nNT280PHXqlMrKyurs94MPPtBvf/tbPfnkkxo7duxZj2fmzJmqqKgwXocOHTprPQAAAC4Mbg3NXl5eioiIUEFBgTHmcDhUUFCg6OjoeteJjo52qZek/Px8oz40NFRBQUEuNZWVlSoqKjJqoqOjVV5eruLiYqNmw4YNcjgcioqKMsbef/99xcfH69FHH3V5ssaZeHt7y9fX1+UFAACAC59b5zRLUlpampKTkxUZGan+/ftr8eLFqqqq0vjx4yVJY8eOVadOnZSVlSVJmjp1qoYMGaJFixYpPj5er7zyirZt26bly5dLkiwWi6ZNm6YFCxaoW7duCg0N1YMPPiibzaaEhARJUlhYmEaMGKEJEyYoOztbJ0+e1OTJk5WYmGg8OWPjxo26/vrrNXXqVI0aNcqY6+zl5cXNgAAAAL8wbg/No0eP1pEjR5SRkSG73a7w8HDl5eUZN/IdPHhQHh7/uyAeExOjNWvWaM6cOZo1a5a6deum3Nxc9erVy6iZMWOGqqqqlJqaqvLycg0cOFB5eXmyWq1GzerVqzV58mQNGzZMHh4eGjVqlJYsWWIsX7Fihb777jtlZWUZgV2ShgwZovfff78ZzwgAAABaGrc/p/lixnOaATQHntMM4GLGc5oBAACACxShGQAAADBBaAYAAABMEJoBAAAAE4RmAAAAwAShGQAAADBBaAYAAABMEJoBAAAAE4RmAAAAwAShGQAAADBBaAYAAABMEJoBAAAAE4RmAAAAwAShGQAAADBBaAYAAABMEJoBAAAAE4RmAAAAwAShGQAAADBBaAYAAABMEJoBAAAAE4RmAAAAwAShGQAAADBBaAYAAABMEJoBAAAAE4RmAAAAwAShGQAAADBBaAYAAABMEJoBAAAAE4RmAAAAwAShGQAAADBBaAYAAABMEJoBAAAAE4RmAAAAwAShGQAAADBBaAYAAABMEJoBAAAAE4RmAAAAwAShGQAAADBBaAYAAABMEJoBAAAAE4RmAAAAwAShGQAAADBBaAYAAABMEJoBAAAAE4RmAAAAwAShGQAAADBBaAYAAABMEJoBAAAAE4RmAAAAwAShGQAAADBBaAYAAABMEJoBAAAAE4RmAAAAwAShGQAAADBBaAYAAABMEJoBAAAAE4RmAAAAwAShGQAAADBBaAYAAABMEJoBAAAAE4RmAAAAwAShGQAAADDRIkLzsmXLFBISIqvVqqioKG3ZsuWs9evWrVOPHj1ktVrVu3dvvfXWWy7LnU6nMjIy1LFjR7Vp00axsbHat2+fS01ZWZnGjBkjX19f+fv7KyUlRcePH3ep+eSTTzRo0CBZrVYFBwdr4cKFTXPAAAAAuKC4PTSvXbtWaWlpyszM1Pbt29WnTx/FxcXp8OHD9dZv3rxZSUlJSklJ0Y4dO5SQkKCEhASVlJQYNQsXLtSSJUuUnZ2toqIi+fj4KC4uTidOnDBqxowZo927dys/P1/r16/Xpk2blJqaaiyvrKzU8OHD1blzZxUXF+uxxx7T3LlztXz58uY7GQAAAGiRLE6n0+nOBqKiotSvXz8tXbpUkuRwOBQcHKwpU6YoPT29Tv3o0aNVVVWl9evXG2MDBgxQeHi4srOz5XQ6ZbPZdN9992n69OmSpIqKCgUGBionJ0eJiYnas2ePevbsqa1btyoyMlKSlJeXp5EjR+qrr76SzWbTM888o9mzZ8tut8vLy0uSlJ6ertzcXO3du7dBx1ZZWSk/Pz9VVFTI19f3Z52nhgpJf/O87AeA+xx4JN7dLbgNn3HAxe98f8Y1NK95nsee6qipqVFxcbFmzpxpjHl4eCg2NlaFhYX1rlNYWKi0tDSXsbi4OOXm5kqS9u/fL7vdrtjYWGO5n5+foqKiVFhYqMTERBUWFsrf398IzJIUGxsrDw8PFRUV6cYbb1RhYaEGDx5sBObT+3n00Uf17bff6rLLLqvTW3V1taqrq433FRUVkn74ZZwvjurvztu+ALjH+fxMaWn4jAMufuf7M+70/syuI7s1NB89elS1tbUKDAx0GQ8MDDzj1Vy73V5vvd1uN5afHjtbTUBAgMtyT09PtWvXzqUmNDS0zjZOL6svNGdlZWnevHl1xoODg+s9FgA4F36L3d0BADQfd33GHTt2TH5+fmdc7tbQfLGZOXOmy1Vwh8OhsrIy/b//9/9ksVjc2BkuVpWVlQoODtahQ4fO2xQgADhf+IzD+eB0OnXs2DHZbLaz1rk1NLdv316tWrVSaWmpy3hpaamCgoLqXScoKOis9ad/lpaWqmPHji414eHhRs1PbzQ8deqUysrKXLZT335+vI+f8vb2lre3t8uYv79/vbVAU/L19eU/KAAuWnzGobmd7QrzaW59eoaXl5ciIiJUUFBgjDkcDhUUFCg6OrredaKjo13qJSk/P9+oDw0NVVBQkEtNZWWlioqKjJro6GiVl5eruLjYqNmwYYMcDoeioqKMmk2bNunkyZMu+7nyyivrnZoBAACAi5fbHzmXlpam5557TitWrNCePXs0adIkVVVVafz48ZKksWPHutwoOHXqVOXl5WnRokXau3ev5s6dq23btmny5MmSJIvFomnTpmnBggV6/fXXtWvXLo0dO1Y2m00JCQmSpLCwMI0YMUITJkzQli1b9NFHH2ny5MlKTEw0Ls3fdttt8vLyUkpKinbv3q21a9fqqaeeqnMTIgAAAC5+bp/TPHr0aB05ckQZGRmy2+0KDw9XXl6ecdPdwYMH5eHxv2wfExOjNWvWaM6cOZo1a5a6deum3Nxc9erVy6iZMWOGqqqqlJqaqvLycg0cOFB5eXmyWq1GzerVqzV58mQNGzZMHh4eGjVqlJYsWWIs9/Pz07vvvqu7775bERERat++vTIyMlye5Qy4m7e3tzIzM+tMCwKAiwGfcWhJ3P6cZgAAAKClc/v0DAAAAKClIzQDAAAAJgjNAAAAgAlCMwAAAGCC0Ay0EMuWLVNISIisVquioqK0ZcuWJtv2f/7zH912223q3r27PDw8NG3atCbbNgCY2bRpk37729/KZrPJYrEoNze3yffxySefaNCgQbJarQoODtbChQubfB/4ZSM0Ay3A2rVrlZaWpszMTG3fvl19+vRRXFxcnW+u/LGDBw82ePvV1dXq0KGD5syZoz59+jRFywDQYFVVVerTp4+WLVvW4HUa8xlXWVmp4cOHq3PnziouLtZjjz2muXPnavny5efSLlAvHjkHtABRUVHq16+fli5dKumHb8YMDg7WlClTlJ6eXu86oaGhCgwMVHJyshITExv8TZVDhw5VeHi4Fi9e3FTtA0CDWSwW/e1vfzO+cOxMrrnmGh05ckTJycm6/fbb1bFjxzPWPvPMM5o9e7bsdru8vLwkSenp6crNzdXevXubsn38gnGlGXCzmpoaFRcXKzY21hjz8PBQbGysCgsLz7jepk2b9Lvf/U5LlixRx44ddeutt+rNN99UbW3t+WgbAJrVq6++qtTUVK1du1bBwcEaOXKk1q5dqxMnTtSpLSws1ODBg43ALElxcXH69NNP9e23357PtnERIzQDbnb06FHV1tYa34J5WmBgoOx2+xnXCw4O1qxZs7Rnzx5t2rRJAQEBGjdunH71q19p+vTpKikpae7WAaDZdOjQQffcc4+2bdumXbt26eqrr9b06dPVsWNHTZw4Uf/85z+NWrvdXu9n6OllQFMgNAMt3MSJE3XJJZcYr/r0799fS5cu1ddff63bbrtNTzzxhG6//fbz3CkANN7DDz/s8hlX31zmsLAwPfLII/ryyy+Vnp6uP//5zxoxYoQbusUvmae7GwB+6dq3b69WrVqptLTUZby0tFRBQUGaP3++pk+fftZtfPrpp1q5cqVWrVqliooKTZgwQSkpKc3ZNgA0iYkTJ+rWW2813ttstjo1hw4d0urVq7Vy5Urt379ft9xyi8aPH28sDwoKqvcz9PQyoCkQmgE38/LyUkREhAoKCowbYxwOhwoKCjR58mQFBAQoICCgznpHjx7VK6+8opUrV6q4uFi/+c1v9MgjjyghIUFWq/U8HwUAnJt27dqpXbt2dcaPHTumv/zlL3rppZf0wQcfKCYmRmlpabrlllvk6+vrUhsdHa3Zs2fr5MmTat26tSQpPz9fV155ZYNvkgbMEJqBFiAtLU3JycmKjIxU//79tXjxYlVVVblcSfmpqKgoWa1WJScnKzc396x3lkvSzp07JUnHjx/XkSNHtHPnTnl5ealnz55NeSgAUMfx48f1+eefG+/379+vnTt3ql27drr88svrXSchIUH//ve/dccdd+i5555Tly5dzrj92267TfPmzVNKSooeeOABlZSU6KmnntKTTz7Z5MeCXy4eOQe0EEuXLtVjjz0mu92u8PBwLVmyRFFRUWes37t3r3r06NHg7VssljpjnTt31oEDB86lXQBosPfff1/XXHNNnfHk5GTl5OTUu86nn36q7t271/vZVZ9PPvlEd999t7Zu3ar27dtrypQpeuCBB35O24ALQjMAAABggqdnAAAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmCA0AwAAACYIzQAAAIAJQjMAAABggtAMAAAAmPj/7D064vedLR0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bit flip direction analysis\n",
    "flip_stats = (\n",
    "    df_rand.groupby([\"original_bit\", \"flipped_bit\"])\n",
    "    .apply(lambda x: (x[\"original_output\"] != x[\"flipped_output\"]).mean())\n",
    "    .reset_index(name=\"error_rate\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(\n",
    "    [\n",
    "        f\"{o}->{f}\"\n",
    "        for o, f in zip(flip_stats[\"original_bit\"], flip_stats[\"flipped_bit\"])\n",
    "    ],\n",
    "    flip_stats[\"error_rate\"],\n",
    ")\n",
    "plt.title(\"Bit Flip Direction Impact\")\n",
    "plt.ylabel(\"Error Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs the same bit-flip testing as before, but instead of randomly selecting layer and bit position, it specifically targets bit position 5 in the first convolutional layer (c1) of the network, allowing for focused analysis of faults in a specific network location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "TARGET_LAYER = \"c1\"\n",
    "TARGET_BIT_POS = 5\n",
    "\n",
    "results_c1_5 = []\n",
    "orig_sd = flenet.state_dict()\n",
    "\n",
    "for inputs, targets in exp_loader:\n",
    "    for input, target in zip(inputs, targets):\n",
    "        input = input.unsqueeze(0)\n",
    "        output = infer(input, flenet)\n",
    "\n",
    "        sd = copy.deepcopy(orig_sd)\n",
    "\n",
    "        layer = get_weight_key(flenet, TARGET_LAYER)\n",
    "        params = to_tensor(sd[layer])\n",
    "        idx = randidx(params)\n",
    "        param = params[idx]\n",
    "\n",
    "        orig_param = quant_to_int8(param)\n",
    "\n",
    "        bit_pos = TARGET_BIT_POS\n",
    "        orig_bit = get_bit(orig_param, bit_pos)\n",
    "        flipped_bit = 1 if orig_bit == 0 else 0\n",
    "\n",
    "        flipped_param = flip_bit(orig_param, bit_pos)\n",
    "\n",
    "        params[idx] = int8_to_quant(\n",
    "            flipped_param, param.q_scale(), param.q_zero_point()\n",
    "        )\n",
    "\n",
    "        flenet.load_state_dict(sd)\n",
    "\n",
    "        flip_output = infer(input, flenet)\n",
    "\n",
    "        results_c1_5.append(\n",
    "            {\n",
    "                \"layer\": clean_layer(layer),\n",
    "                \"bit_position\": bit_pos,\n",
    "                \"original_bit\": orig_bit,\n",
    "                \"flipped_bit\": flipped_bit,\n",
    "                \"original_param\": orig_param,\n",
    "                \"flipped_param\": flipped_param,\n",
    "                \"original_output\": output.item(),\n",
    "                \"flipped_output\": flip_output.item(),\n",
    "                \"target_output\": target.item(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        flenet.load_state_dict(orig_sd)\n",
    "\n",
    "df_c1_5 = pd.DataFrame(results_c1_5)\n",
    "df_c1_5.to_csv(\"results_c1_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>bit_position</th>\n",
       "      <th>original_bit</th>\n",
       "      <th>flipped_bit</th>\n",
       "      <th>original_param</th>\n",
       "      <th>flipped_param</th>\n",
       "      <th>original_output</th>\n",
       "      <th>flipped_output</th>\n",
       "      <th>target_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-41</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-97</td>\n",
       "      <td>-65</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-102</td>\n",
       "      <td>-70</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-24</td>\n",
       "      <td>-56</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-36</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-34</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-12</td>\n",
       "      <td>-44</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>117</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-64</td>\n",
       "      <td>-32</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-33</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3893</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-13</td>\n",
       "      <td>-45</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4248</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-34</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4761</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-43</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6011</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-20</td>\n",
       "      <td>-52</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-17</td>\n",
       "      <td>-49</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6578</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6625</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-40</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-32</td>\n",
       "      <td>-64</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7856</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7905</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8332</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-32</td>\n",
       "      <td>-64</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9777</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-35</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     layer  bit_position  original_bit  flipped_bit original_param  \\\n",
       "287     c1             5             1            0             -9   \n",
       "359     c1             5             0            1            -97   \n",
       "435     c1             5             1            0             54   \n",
       "659     c1             5             0            1              6   \n",
       "916     c1             5             0            1             12   \n",
       "1248    c1             5             1            0             63   \n",
       "1364    c1             5             0            1           -102   \n",
       "1822    c1             5             0            1             29   \n",
       "2189    c1             5             1            0            -24   \n",
       "2280    c1             5             1            0             -4   \n",
       "2414    c1             5             1            0             -2   \n",
       "2695    c1             5             1            0            -12   \n",
       "2721    c1             5             0            1             85   \n",
       "2836    c1             5             1            0             97   \n",
       "2959    c1             5             0            1            -64   \n",
       "3005    c1             5             1            0             -1   \n",
       "3288    c1             5             0            1              3   \n",
       "3441    c1             5             1            0             40   \n",
       "3749    c1             5             0            1             87   \n",
       "3893    c1             5             0            1              6   \n",
       "4078    c1             5             1            0            -13   \n",
       "4223    c1             5             0            1             21   \n",
       "4248    c1             5             1            0             -2   \n",
       "4455    c1             5             1            0             36   \n",
       "4500    c1             5             0            1             29   \n",
       "4731    c1             5             0            1              8   \n",
       "4761    c1             5             1            0             97   \n",
       "4783    c1             5             1            0            -11   \n",
       "6011    c1             5             1            0            -20   \n",
       "6173    c1             5             1            0            -17   \n",
       "6578    c1             5             0            1             12   \n",
       "6625    c1             5             1            0             -8   \n",
       "7216    c1             5             1            0            -32   \n",
       "7856    c1             5             0            1             22   \n",
       "7905    c1             5             1            0             57   \n",
       "8332    c1             5             1            0            -32   \n",
       "8527    c1             5             1            0             51   \n",
       "9777    c1             5             0            1            -35   \n",
       "\n",
       "      flipped_param  original_output  flipped_output  target_output  \n",
       "287             -41                2               4              4  \n",
       "359             -65                4               9              9  \n",
       "435              22                9               8              8  \n",
       "659              38                1               7              2  \n",
       "916              44                4               2              4  \n",
       "1248             31                2               8              8  \n",
       "1364            -70                2               8              8  \n",
       "1822             61                6               5              6  \n",
       "2189            -56                9               7              9  \n",
       "2280            -36                3               0              3  \n",
       "2414            -34                4               8              9  \n",
       "2695            -44                7               3              7  \n",
       "2721            117                6               5              6  \n",
       "2836             65                2               4              4  \n",
       "2959            -32                3               2              2  \n",
       "3005            -33                9               4              9  \n",
       "3288             35                9               4              4  \n",
       "3441              8                7               2              7  \n",
       "3749            119                0               6              6  \n",
       "3893             38                8               5              5  \n",
       "4078            -45                9               8              9  \n",
       "4223             53                4               2              4  \n",
       "4248            -34                2               0              2  \n",
       "4455              4                8               0              8  \n",
       "4500             61                9               1              9  \n",
       "4731             40                2               7              8  \n",
       "4761             65                4               7              9  \n",
       "4783            -43                4               9              4  \n",
       "6011            -52                3               8              3  \n",
       "6173            -49                4               8              9  \n",
       "6578             44                5               8              8  \n",
       "6625            -40                0               2              8  \n",
       "7216            -64                6               0              0  \n",
       "7856             54                8               1              1  \n",
       "7905             25                2               3              3  \n",
       "8332            -64                9               1              9  \n",
       "8527             19                9               4              4  \n",
       "9777             -3                3               5              5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_5_errors_df = df_c1_5[df_c1_5[\"original_output\"] != df_c1_5[\"flipped_output\"]]\n",
    "\n",
    "c1_5_errors_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
