{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5 Fault Injection\n",
    "\n",
    "This code implements fault injection testing on a quantized LeNet-5 convolutional neural network using PyTorch. The network is trained on the MNIST dataset, quantized to 8-bit integers, and systematically tested by flipping individual bits in its parameters. The testing framework allows both random bit flips across all layers and targeted testing of specific layers and bit positions, measuring how these faults impact the model's classification accuracy.\n",
    "\n",
    "![framework](framework.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python and PyTorch make it easy to modify neural network parameters during runtime testing. PyTorch directly exposes quantized weights through its API, while TensorFlow doesn't allow modifying weights after quantization. Using established ML frameworks like PyTorch also leverages years of development and testing by the community, saving time and avoiding common pitfalls that others have already solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch requires defining forward to specify data flow through network layers - it's called automatically when you run lenet(input). The code inherits from nn.Module for automatic gradient computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Lenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.s2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.c3 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.s4 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.f5 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.f6 = nn.Linear(120, 84)\n",
    "        self.f7 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.c1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.s2(x)\n",
    "        x = self.c3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.s4(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.f5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.f6(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.f7(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "lenet = Lenet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets up data loading for the MNIST dataset. `NUM_WORKERS` is set to optimize CPU usage (max 4 threads) and batch size is 64. The transforms prep images by:\n",
    "- Converting to tensors\n",
    "- Normalizing with MNIST's mean (0.1307) and std (0.3081) \n",
    "- Adding 2-pixel padding to match LeNet input size\n",
    "\n",
    "The MNIST dataset is downloaded and split:\n",
    "- Test set (standard split)\n",
    "- Training set split into 80% train, 20% validation\n",
    "\n",
    "`DataLoader` wraps these datasets to enable batch processing with specified workers. Training data is shuffled, validation/test aren't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "NUM_WORKERS = min(4, os.cpu_count())\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "transform = T.Compose(\n",
    "    [\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.1307,), (0.3081,)),\n",
    "        T.Pad(2),\n",
    "    ]\n",
    ")\n",
    "train_set = datasets.MNIST(\"tmp/data\", train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST(\"tmp/data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(train_set))\n",
    "val_size = len(train_set) - train_size\n",
    "\n",
    "train_set, val_set = random_split(train_set, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_set, BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "exp_loader = DataLoader(test_set, BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function evaluates model accuracy by running inference in evaluation mode (`model.eval()`), disabling gradients for efficiency, and calculating the percentage of correct predictions by comparing model outputs against target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model: nn.Module, loader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    total = correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input, target in loader:\n",
    "            output = model(input)\n",
    "            pred = torch.argmax(output, dim=1)\n",
    "            total += target.size(0)\n",
    "            correct += (pred == target).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop running for 3 epochs using Adam optimizer with learning rate 0.01. Each iteration zeros gradients, runs forward pass through LeNet, calculates cross-entropy loss between predictions and targets, backpropagates gradients (loss.backward()), and updates model weights (optimizer.step()). Progress prints every 100 batches. Finally tests model accuracy on test set using previously defined calculate_accuracy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINING] epoch=1 batch=0 loss=2.30\n",
      "[TRAINING] epoch=1 batch=100 loss=0.03\n",
      "[TRAINING] epoch=1 batch=200 loss=0.10\n",
      "[TRAINING] epoch=1 batch=300 loss=0.09\n",
      "[TRAINING] epoch=1 batch=400 loss=0.15\n",
      "[TRAINING] epoch=1 batch=500 loss=0.12\n",
      "[TRAINING] epoch=1 batch=600 loss=0.10\n",
      "[TRAINING] epoch=1 batch=700 loss=0.11\n",
      "[TRAINING] epoch=2 batch=0 loss=0.09\n",
      "[TRAINING] epoch=2 batch=100 loss=0.03\n",
      "[TRAINING] epoch=2 batch=200 loss=0.21\n",
      "[TRAINING] epoch=2 batch=300 loss=0.04\n",
      "[TRAINING] epoch=2 batch=400 loss=0.06\n",
      "[TRAINING] epoch=2 batch=500 loss=0.06\n",
      "[TRAINING] epoch=2 batch=600 loss=0.08\n",
      "[TRAINING] epoch=2 batch=700 loss=0.05\n",
      "[TRAINING] epoch=3 batch=0 loss=0.12\n",
      "[TRAINING] epoch=3 batch=100 loss=0.01\n",
      "[TRAINING] epoch=3 batch=200 loss=0.20\n",
      "[TRAINING] epoch=3 batch=300 loss=0.07\n",
      "[TRAINING] epoch=3 batch=400 loss=0.08\n",
      "[TRAINING] epoch=3 batch=500 loss=0.12\n",
      "[TRAINING] epoch=3 batch=600 loss=0.19\n",
      "[TRAINING] epoch=3 batch=700 loss=0.01\n",
      "[TESTING] accuracy=98.21%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "optimizer = optim.Adam(lenet.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "lenet.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (input, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        flip_output = lenet(input)\n",
    "        loss = F.cross_entropy(flip_output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"[TRAINING] epoch={epoch + 1} batch={batch_idx} loss={loss.item():.2f}\"\n",
    "            )\n",
    "\n",
    "\n",
    "print(f\"[TESTING] accuracy={(100 * calculate_accuracy(lenet, exp_loader)):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves trained LeNet model's parameters (weights and biases) to a file named \"lenet.pt\" using PyTorch's save function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENET_PATH = \"lenet.pt\"\n",
    "\n",
    "torch.save(lenet.state_dict(), LENET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a quantization-ready version of LeNet by subclassing it. QLenet adds quantization (QuantStub) and dequantization (DeQuantStub) layers around the original network's forward pass. These stubs mark where PyTorch should convert between floating-point and quantized (8-bit integer) representations. The model loads weights from the previously saved LeNet using load_state_dict, with weights_only=True to ignore any saved optimizer state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "\n",
    "\n",
    "class QLenet(Lenet):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.quant(x)\n",
    "        x = super().forward(x)\n",
    "        x = self.dequant(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "qlenet = QLenet()\n",
    "\n",
    "qlenet.load_state_dict(torch.load(LENET_PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code configures quantization using Facebook's FBGEMM backend, prepares the model for quantization, then calibrates it by running validation data through the network to collect statistics about activation ranges. Finally, it converts the model to use quantized (8-bit) weights and tests its accuracy. The `inplace=True` parameter modifies the model directly instead of creating copies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/lenet/.venv/lib/python3.11/site-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CALIBRATING] batch=0\n",
      "[CALIBRATING] batch=1\n",
      "[CALIBRATING] batch=2\n",
      "[CALIBRATING] batch=3\n",
      "[CALIBRATING] batch=4\n",
      "[CALIBRATING] batch=5\n",
      "[CALIBRATING] batch=6\n",
      "[CALIBRATING] batch=7\n",
      "[CALIBRATING] batch=8\n",
      "[CALIBRATING] batch=9\n",
      "[CALIBRATING] batch=10\n",
      "[CALIBRATING] batch=11\n",
      "[CALIBRATING] batch=12\n",
      "[CALIBRATING] batch=13\n",
      "[CALIBRATING] batch=14\n",
      "[CALIBRATING] batch=15\n",
      "[CALIBRATING] batch=16\n",
      "[CALIBRATING] batch=17\n",
      "[CALIBRATING] batch=18\n",
      "[CALIBRATING] batch=19\n",
      "[CALIBRATING] batch=20\n",
      "[CALIBRATING] batch=21\n",
      "[CALIBRATING] batch=22\n",
      "[CALIBRATING] batch=23\n",
      "[CALIBRATING] batch=24\n",
      "[CALIBRATING] batch=25\n",
      "[CALIBRATING] batch=26\n",
      "[CALIBRATING] batch=27\n",
      "[CALIBRATING] batch=28\n",
      "[CALIBRATING] batch=29\n",
      "[CALIBRATING] batch=30\n",
      "[CALIBRATING] batch=31\n",
      "[CALIBRATING] batch=32\n",
      "[CALIBRATING] batch=33\n",
      "[CALIBRATING] batch=34\n",
      "[CALIBRATING] batch=35\n",
      "[CALIBRATING] batch=36\n",
      "[CALIBRATING] batch=37\n",
      "[CALIBRATING] batch=38\n",
      "[CALIBRATING] batch=39\n",
      "[CALIBRATING] batch=40\n",
      "[CALIBRATING] batch=41\n",
      "[CALIBRATING] batch=42\n",
      "[CALIBRATING] batch=43\n",
      "[CALIBRATING] batch=44\n",
      "[CALIBRATING] batch=45\n",
      "[CALIBRATING] batch=46\n",
      "[CALIBRATING] batch=47\n",
      "[CALIBRATING] batch=48\n",
      "[CALIBRATING] batch=49\n",
      "[CALIBRATING] batch=50\n",
      "[CALIBRATING] batch=51\n",
      "[CALIBRATING] batch=52\n",
      "[CALIBRATING] batch=53\n",
      "[CALIBRATING] batch=54\n",
      "[CALIBRATING] batch=55\n",
      "[CALIBRATING] batch=56\n",
      "[CALIBRATING] batch=57\n",
      "[CALIBRATING] batch=58\n",
      "[CALIBRATING] batch=59\n",
      "[CALIBRATING] batch=60\n",
      "[CALIBRATING] batch=61\n",
      "[CALIBRATING] batch=62\n",
      "[CALIBRATING] batch=63\n",
      "[CALIBRATING] batch=64\n",
      "[CALIBRATING] batch=65\n",
      "[CALIBRATING] batch=66\n",
      "[CALIBRATING] batch=67\n",
      "[CALIBRATING] batch=68\n",
      "[CALIBRATING] batch=69\n",
      "[CALIBRATING] batch=70\n",
      "[CALIBRATING] batch=71\n",
      "[CALIBRATING] batch=72\n",
      "[CALIBRATING] batch=73\n",
      "[CALIBRATING] batch=74\n",
      "[CALIBRATING] batch=75\n",
      "[CALIBRATING] batch=76\n",
      "[CALIBRATING] batch=77\n",
      "[CALIBRATING] batch=78\n",
      "[CALIBRATING] batch=79\n",
      "[CALIBRATING] batch=80\n",
      "[CALIBRATING] batch=81\n",
      "[CALIBRATING] batch=82\n",
      "[CALIBRATING] batch=83\n",
      "[CALIBRATING] batch=84\n",
      "[CALIBRATING] batch=85\n",
      "[CALIBRATING] batch=86\n",
      "[CALIBRATING] batch=87\n",
      "[CALIBRATING] batch=88\n",
      "[CALIBRATING] batch=89\n",
      "[CALIBRATING] batch=90\n",
      "[CALIBRATING] batch=91\n",
      "[CALIBRATING] batch=92\n",
      "[CALIBRATING] batch=93\n",
      "[CALIBRATING] batch=94\n",
      "[CALIBRATING] batch=95\n",
      "[CALIBRATING] batch=96\n",
      "[CALIBRATING] batch=97\n",
      "[CALIBRATING] batch=98\n",
      "[CALIBRATING] batch=99\n",
      "[CALIBRATING] batch=100\n",
      "[CALIBRATING] batch=101\n",
      "[CALIBRATING] batch=102\n",
      "[CALIBRATING] batch=103\n",
      "[CALIBRATING] batch=104\n",
      "[CALIBRATING] batch=105\n",
      "[CALIBRATING] batch=106\n",
      "[CALIBRATING] batch=107\n",
      "[CALIBRATING] batch=108\n",
      "[CALIBRATING] batch=109\n",
      "[CALIBRATING] batch=110\n",
      "[CALIBRATING] batch=111\n",
      "[CALIBRATING] batch=112\n",
      "[CALIBRATING] batch=113\n",
      "[CALIBRATING] batch=114\n",
      "[CALIBRATING] batch=115\n",
      "[CALIBRATING] batch=116\n",
      "[CALIBRATING] batch=117\n",
      "[CALIBRATING] batch=118\n",
      "[CALIBRATING] batch=119\n",
      "[CALIBRATING] batch=120\n",
      "[CALIBRATING] batch=121\n",
      "[CALIBRATING] batch=122\n",
      "[CALIBRATING] batch=123\n",
      "[CALIBRATING] batch=124\n",
      "[CALIBRATING] batch=125\n",
      "[CALIBRATING] batch=126\n",
      "[CALIBRATING] batch=127\n",
      "[CALIBRATING] batch=128\n",
      "[CALIBRATING] batch=129\n",
      "[CALIBRATING] batch=130\n",
      "[CALIBRATING] batch=131\n",
      "[CALIBRATING] batch=132\n",
      "[CALIBRATING] batch=133\n",
      "[CALIBRATING] batch=134\n",
      "[CALIBRATING] batch=135\n",
      "[CALIBRATING] batch=136\n",
      "[CALIBRATING] batch=137\n",
      "[CALIBRATING] batch=138\n",
      "[CALIBRATING] batch=139\n",
      "[CALIBRATING] batch=140\n",
      "[CALIBRATING] batch=141\n",
      "[CALIBRATING] batch=142\n",
      "[CALIBRATING] batch=143\n",
      "[CALIBRATING] batch=144\n",
      "[CALIBRATING] batch=145\n",
      "[CALIBRATING] batch=146\n",
      "[CALIBRATING] batch=147\n",
      "[CALIBRATING] batch=148\n",
      "[CALIBRATING] batch=149\n",
      "[CALIBRATING] batch=150\n",
      "[CALIBRATING] batch=151\n",
      "[CALIBRATING] batch=152\n",
      "[CALIBRATING] batch=153\n",
      "[CALIBRATING] batch=154\n",
      "[CALIBRATING] batch=155\n",
      "[CALIBRATING] batch=156\n",
      "[CALIBRATING] batch=157\n",
      "[CALIBRATING] batch=158\n",
      "[CALIBRATING] batch=159\n",
      "[CALIBRATING] batch=160\n",
      "[CALIBRATING] batch=161\n",
      "[CALIBRATING] batch=162\n",
      "[CALIBRATING] batch=163\n",
      "[CALIBRATING] batch=164\n",
      "[CALIBRATING] batch=165\n",
      "[CALIBRATING] batch=166\n",
      "[CALIBRATING] batch=167\n",
      "[CALIBRATING] batch=168\n",
      "[CALIBRATING] batch=169\n",
      "[CALIBRATING] batch=170\n",
      "[CALIBRATING] batch=171\n",
      "[CALIBRATING] batch=172\n",
      "[CALIBRATING] batch=173\n",
      "[CALIBRATING] batch=174\n",
      "[CALIBRATING] batch=175\n",
      "[CALIBRATING] batch=176\n",
      "[CALIBRATING] batch=177\n",
      "[CALIBRATING] batch=178\n",
      "[CALIBRATING] batch=179\n",
      "[CALIBRATING] batch=180\n",
      "[CALIBRATING] batch=181\n",
      "[CALIBRATING] batch=182\n",
      "[CALIBRATING] batch=183\n",
      "[CALIBRATING] batch=184\n",
      "[CALIBRATING] batch=185\n",
      "[CALIBRATING] batch=186\n",
      "[CALIBRATING] batch=187\n",
      "[TESTING] accuracy=98.05%\n"
     ]
    }
   ],
   "source": [
    "import torch.quantization as quantization\n",
    "\n",
    "BACKEND = \"fbgemm\"\n",
    "\n",
    "qlenet.qconfig = quantization.get_default_qconfig(BACKEND)\n",
    "quantization.prepare(qlenet, inplace=True)\n",
    "\n",
    "qlenet.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (input, _) in enumerate(val_loader):\n",
    "        qlenet(input)\n",
    "        print(f\"[CALIBRATING] batch={batch_idx}\")\n",
    "\n",
    "quantization.convert(qlenet, inplace=True)\n",
    "\n",
    "quant_accuracy = 100 * calculate_accuracy(qlenet, exp_loader)\n",
    "print(f\"[TESTING] accuracy={quant_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves the quantized LeNet model's state dictionary to \"qlenet.pt\" file, preserving the quantized weights and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "QLENET_PATH = \"qlenet.pt\"\n",
    "\n",
    "torch.save(qlenet.state_dict(), QLENET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code recreates a new quantization-ready LeNet (flenet), prepares and converts it for quantization without calibration, then loads the previously saved quantized weights from \"qlenet.pt\". This way the model starts directly with quantized weights instead of needing recalibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/lenet/.venv/lib/python3.11/site-packages/torch/ao/quantization/observer.py:1315: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n",
      "/workspaces/lenet/.venv/lib/python3.11/site-packages/torch/_utils.py:413: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flenet = QLenet()\n",
    "\n",
    "flenet.qconfig = quantization.get_default_qconfig(BACKEND)\n",
    "quantization.prepare(flenet, inplace=True)\n",
    "quantization.convert(flenet, inplace=True)\n",
    "\n",
    "flenet.load_state_dict(torch.load(QLENET_PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are utility functions for manipulating quantized model weights, including bit flipping, layer selection, tensor conversion, and quantization operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Tuple\n",
    "import numpy as np\n",
    "from torch import quantize_per_tensor\n",
    "import random\n",
    "\n",
    "\n",
    "def get_weight_key(model: nn.Module, attr: str) -> str:\n",
    "    \"\"\"Retrieves the appropriate weight key for accessing model parameters based on layer type.\n",
    "\n",
    "    Args:\n",
    "        model: Neural network module\n",
    "        attr: Layer attribute name\n",
    "\n",
    "    Returns:\n",
    "        String key to access weights in state dict\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If layer type is not supported (not Conv2d or Linear)\n",
    "    \"\"\"\n",
    "    module = getattr(model, attr)\n",
    "    if isinstance(module, torch.ao.nn.quantized.modules.conv.Conv2d):\n",
    "        return f\"{attr}.weight\"\n",
    "    elif isinstance(module, torch.ao.nn.quantized.modules.linear.Linear):\n",
    "        return f\"{attr}._packed_params._packed_params\"\n",
    "    raise ValueError(f\"Unsupported module type: {type(module)}\")\n",
    "\n",
    "\n",
    "def get_bit(byte: np.int8, pos: int) -> np.int8:\n",
    "    \"\"\"Extracts the bit at specified position from an 8-bit integer.\n",
    "\n",
    "    Args:\n",
    "        byte: 8-bit integer input\n",
    "        pos: Bit position to extract (0-7)\n",
    "\n",
    "    Returns:\n",
    "        Value of bit at specified position (0 or 1)\n",
    "    \"\"\"\n",
    "    return np.bitwise_and(np.right_shift(byte, pos), np.int8(1))\n",
    "\n",
    "\n",
    "def flip_bit(byte: np.int8, pos: int) -> np.int8:\n",
    "    \"\"\"Flips (inverts) the bit at specified position in an 8-bit integer.\n",
    "\n",
    "    Args:\n",
    "        byte: 8-bit integer input\n",
    "        pos: Position of bit to flip (0-7)\n",
    "\n",
    "    Returns:\n",
    "        New 8-bit integer with specified bit flipped\n",
    "    \"\"\"\n",
    "    return np.bitwise_xor(byte, np.left_shift(np.int8(1), pos))\n",
    "\n",
    "\n",
    "# Tuple of suffixes used to identify weight parameters in state dict\n",
    "WEIGHT_SUFFIXES = (\".weight\", \"._packed_params._packed_params\")\n",
    "\n",
    "\n",
    "def randlayer(sd: Dict[str, Any]) -> torch.Tensor:\n",
    "    \"\"\"Randomly selects a layer from model state dictionary.\n",
    "\n",
    "    Args:\n",
    "        sd: Model state dictionary\n",
    "\n",
    "    Returns:\n",
    "        Key of randomly selected layer\n",
    "    \"\"\"\n",
    "    layers = [k for k in sd.keys() if k.endswith(WEIGHT_SUFFIXES)]\n",
    "    return random.choice(layers)\n",
    "\n",
    "\n",
    "def clean_layer(layer: str) -> str:\n",
    "    \"\"\"Removes weight-related suffixes from layer name.\n",
    "\n",
    "    Args:\n",
    "        layer: Full layer name with suffix\n",
    "\n",
    "    Returns:\n",
    "        Clean layer name without suffix\n",
    "    \"\"\"\n",
    "    for suffix in WEIGHT_SUFFIXES:\n",
    "        layer = layer.removesuffix(suffix)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def to_tensor(param) -> torch.Tensor:\n",
    "    \"\"\"Converts parameter to tensor if not already.\n",
    "\n",
    "    Args:\n",
    "        param: Model parameter (tensor or tuple)\n",
    "\n",
    "    Returns:\n",
    "        Parameter as tensor\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If parameter type is not supported\n",
    "    \"\"\"\n",
    "    if isinstance(param, torch.Tensor):\n",
    "        return param\n",
    "    elif isinstance(param, tuple) and len(param) > 0:\n",
    "        return param[0]\n",
    "    raise ValueError(f\"Unsupported parameter type: {type(param)}\")\n",
    "\n",
    "\n",
    "def randidx(tensor: torch.Tensor) -> Tuple[int, ...]:\n",
    "    \"\"\"Generates random indices for each dimension of tensor.\n",
    "\n",
    "    Args:\n",
    "        tensor: Input tensor\n",
    "\n",
    "    Returns:\n",
    "        Tuple of random indices matching tensor dimensions\n",
    "    \"\"\"\n",
    "    return tuple(random.randint(0, s - 1) for s in tensor.shape)\n",
    "\n",
    "\n",
    "def randbitpos() -> int:\n",
    "    \"\"\"Generates random bit position (0-7) for 8-bit integer.\n",
    "\n",
    "    Returns:\n",
    "        Random integer between 0 and 7\n",
    "    \"\"\"\n",
    "    return random.randint(0, 7)\n",
    "\n",
    "\n",
    "def dequant_int8(val: np.int8, scale: float, zero_point: int) -> float:\n",
    "    \"\"\"Dequantizes 8-bit integer to floating point value.\n",
    "\n",
    "    Args:\n",
    "        val: Quantized 8-bit value\n",
    "        scale: Quantization scale factor\n",
    "        zero_point: Quantization zero point\n",
    "\n",
    "    Returns:\n",
    "        Dequantized floating point value\n",
    "    \"\"\"\n",
    "    return float(val - zero_point) * scale\n",
    "\n",
    "\n",
    "def quant_to_int8(tensor: torch.Tensor) -> np.int8:\n",
    "    \"\"\"Converts quantized tensor to 8-bit integer representation.\n",
    "\n",
    "    Args:\n",
    "        tensor: Quantized input tensor\n",
    "\n",
    "    Returns:\n",
    "        NumPy array of 8-bit integers\n",
    "    \"\"\"\n",
    "    return tensor.int_repr().numpy().astype(np.int8)\n",
    "\n",
    "\n",
    "def int8_to_quant(input: np.int8, scale: float, zero_point: int) -> torch.Tensor:\n",
    "    \"\"\"Converts 8-bit integer to quantized tensor.\n",
    "\n",
    "    Args:\n",
    "        input: 8-bit integer input\n",
    "        scale: Quantization scale factor\n",
    "        zero_point: Quantization zero point\n",
    "\n",
    "    Returns:\n",
    "        Quantized tensor\n",
    "    \"\"\"\n",
    "    return quantize_per_tensor(\n",
    "        torch.tensor(dequant_int8(input, scale, zero_point), dtype=torch.float32),\n",
    "        scale,\n",
    "        zero_point,\n",
    "        torch.qint8,\n",
    "    )\n",
    "\n",
    "\n",
    "def infer(input: torch.Tensor, model: nn.Module) -> torch.Tensor:\n",
    "    \"\"\"Performs inference using quantized model.\n",
    "\n",
    "    Args:\n",
    "        input: Input tensor\n",
    "        model: Neural network model\n",
    "\n",
    "    Returns:\n",
    "        Model prediction (argmax of output)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        return torch.argmax(model(input), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a DataLoader for test dataset with specified batch size and number of worker threads for parallel data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_loader = DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs fault injection testing on a quantized neural network by iterating through test data, randomly selecting and flipping bits in model parameters, and recording the impact on model outputs. For each input image, it creates a copy of the model's state, randomly selects a layer and parameter, flips a random bit in that parameter, runs inference with the modified model, and stores the results (including layer information, bit positions, original and flipped parameter values, and model outputs) in a DataFrame that's ultimately saved to a CSV file. After each test, it restores the model to its original state before proceeding to the next input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "NUM_EXPERIMENTS = 10\n",
    "\n",
    "# Initialize empty results list and get original model state\n",
    "results_rand = []\n",
    "orig_sd = flenet.state_dict()\n",
    "\n",
    "for _ in range(NUM_EXPERIMENTS):\n",
    "    # Iterate through test data batches\n",
    "    for inputs, targets in exp_loader:\n",
    "        # Process each input image and target\n",
    "        for input, target in zip(inputs, targets):\n",
    "            input = input.unsqueeze(0)  # Add batch dimension\n",
    "            output = infer(input, flenet)  # Get original model prediction\n",
    "\n",
    "            sd = copy.deepcopy(orig_sd)  # Create copy of model state\n",
    "\n",
    "            # Randomly select layer and parameter to modify\n",
    "            layer = randlayer(sd)\n",
    "            params = to_tensor(sd[layer])\n",
    "            idx = randidx(params)  # Get random parameter index\n",
    "            param = params[idx]  # Get parameter at index\n",
    "\n",
    "            orig_param = quant_to_int8(param)  # Convert to 8-bit int\n",
    "\n",
    "            # Select random bit and get original value\n",
    "            bit_pos = randbitpos()\n",
    "            orig_bit = get_bit(orig_param, bit_pos)\n",
    "            flipped_bit = 1 if orig_bit == 0 else 0\n",
    "\n",
    "            # Create parameter with flipped bit\n",
    "            flipped_param = flip_bit(orig_param, bit_pos)\n",
    "\n",
    "            # Convert back to quantized tensor and update model\n",
    "            params[idx] = int8_to_quant(\n",
    "                flipped_param, param.q_scale(), param.q_zero_point()\n",
    "            )\n",
    "\n",
    "            flenet.load_state_dict(sd)  # Load modified state\n",
    "\n",
    "            flip_output = infer(input, flenet)  # Get prediction with flipped bit\n",
    "\n",
    "            # Store results of this test\n",
    "            results_rand.append(\n",
    "                {\n",
    "                    \"layer\": clean_layer(layer),\n",
    "                    \"bit_position\": bit_pos,\n",
    "                    \"original_bit\": orig_bit,\n",
    "                    \"flipped_bit\": flipped_bit,\n",
    "                    \"original_param\": orig_param,\n",
    "                    \"flipped_param\": flipped_param,\n",
    "                    \"original_output\": output.item(),\n",
    "                    \"flipped_output\": flip_output.item(),\n",
    "                    \"target_output\": target.item(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            flenet.load_state_dict(orig_sd)  # Restore original state\n",
    "\n",
    "# Convert results to DataFrame and save\n",
    "df_rand = pd.DataFrame(results_rand)\n",
    "df_rand.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate table for the impact of all bit positions across all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 4 saved as 'table_4.csv'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8f1cc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_8f1cc_level0_col0\" class=\"col_heading level0 col0\" >layer</th>\n",
       "      <th id=\"T_8f1cc_level0_col1\" class=\"col_heading level0 col1\" >bit_position</th>\n",
       "      <th id=\"T_8f1cc_level0_col2\" class=\"col_heading level0 col2\" >samples</th>\n",
       "      <th id=\"T_8f1cc_level0_col3\" class=\"col_heading level0 col3\" >errors</th>\n",
       "      <th id=\"T_8f1cc_level0_col4\" class=\"col_heading level0 col4\" >error_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row0_col0\" class=\"data row0 col0\" >c1</td>\n",
       "      <td id=\"T_8f1cc_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_8f1cc_row0_col2\" class=\"data row0 col2\" >2505</td>\n",
       "      <td id=\"T_8f1cc_row0_col3\" class=\"data row0 col3\" >4</td>\n",
       "      <td id=\"T_8f1cc_row0_col4\" class=\"data row0 col4\" >0.1597%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row1_col0\" class=\"data row1 col0\" >c1</td>\n",
       "      <td id=\"T_8f1cc_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "      <td id=\"T_8f1cc_row1_col2\" class=\"data row1 col2\" >2617</td>\n",
       "      <td id=\"T_8f1cc_row1_col3\" class=\"data row1 col3\" >7</td>\n",
       "      <td id=\"T_8f1cc_row1_col4\" class=\"data row1 col4\" >0.2675%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row2_col0\" class=\"data row2 col0\" >c1</td>\n",
       "      <td id=\"T_8f1cc_row2_col1\" class=\"data row2 col1\" >2</td>\n",
       "      <td id=\"T_8f1cc_row2_col2\" class=\"data row2 col2\" >2578</td>\n",
       "      <td id=\"T_8f1cc_row2_col3\" class=\"data row2 col3\" >5</td>\n",
       "      <td id=\"T_8f1cc_row2_col4\" class=\"data row2 col4\" >0.1939%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row3_col0\" class=\"data row3 col0\" >c1</td>\n",
       "      <td id=\"T_8f1cc_row3_col1\" class=\"data row3 col1\" >3</td>\n",
       "      <td id=\"T_8f1cc_row3_col2\" class=\"data row3 col2\" >2505</td>\n",
       "      <td id=\"T_8f1cc_row3_col3\" class=\"data row3 col3\" >12</td>\n",
       "      <td id=\"T_8f1cc_row3_col4\" class=\"data row3 col4\" >0.479%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row4_col0\" class=\"data row4 col0\" >c1</td>\n",
       "      <td id=\"T_8f1cc_row4_col1\" class=\"data row4 col1\" >4</td>\n",
       "      <td id=\"T_8f1cc_row4_col2\" class=\"data row4 col2\" >2452</td>\n",
       "      <td id=\"T_8f1cc_row4_col3\" class=\"data row4 col3\" >8</td>\n",
       "      <td id=\"T_8f1cc_row4_col4\" class=\"data row4 col4\" >0.3263%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row5_col0\" class=\"data row5 col0\" >c1</td>\n",
       "      <td id=\"T_8f1cc_row5_col1\" class=\"data row5 col1\" >5</td>\n",
       "      <td id=\"T_8f1cc_row5_col2\" class=\"data row5 col2\" >2499</td>\n",
       "      <td id=\"T_8f1cc_row5_col3\" class=\"data row5 col3\" >13</td>\n",
       "      <td id=\"T_8f1cc_row5_col4\" class=\"data row5 col4\" >0.5202%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row6_col0\" class=\"data row6 col0\" >c1</td>\n",
       "      <td id=\"T_8f1cc_row6_col1\" class=\"data row6 col1\" >6</td>\n",
       "      <td id=\"T_8f1cc_row6_col2\" class=\"data row6 col2\" >2475</td>\n",
       "      <td id=\"T_8f1cc_row6_col3\" class=\"data row6 col3\" >17</td>\n",
       "      <td id=\"T_8f1cc_row6_col4\" class=\"data row6 col4\" >0.6869%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row7_col0\" class=\"data row7 col0\" >c1</td>\n",
       "      <td id=\"T_8f1cc_row7_col1\" class=\"data row7 col1\" >7</td>\n",
       "      <td id=\"T_8f1cc_row7_col2\" class=\"data row7 col2\" >2505</td>\n",
       "      <td id=\"T_8f1cc_row7_col3\" class=\"data row7 col3\" >21</td>\n",
       "      <td id=\"T_8f1cc_row7_col4\" class=\"data row7 col4\" >0.8383%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row8_col0\" class=\"data row8 col0\" >c3</td>\n",
       "      <td id=\"T_8f1cc_row8_col1\" class=\"data row8 col1\" >0</td>\n",
       "      <td id=\"T_8f1cc_row8_col2\" class=\"data row8 col2\" >2540</td>\n",
       "      <td id=\"T_8f1cc_row8_col3\" class=\"data row8 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row8_col4\" class=\"data row8 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row9_col0\" class=\"data row9 col0\" >c3</td>\n",
       "      <td id=\"T_8f1cc_row9_col1\" class=\"data row9 col1\" >1</td>\n",
       "      <td id=\"T_8f1cc_row9_col2\" class=\"data row9 col2\" >2495</td>\n",
       "      <td id=\"T_8f1cc_row9_col3\" class=\"data row9 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row9_col4\" class=\"data row9 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row10_col0\" class=\"data row10 col0\" >c3</td>\n",
       "      <td id=\"T_8f1cc_row10_col1\" class=\"data row10 col1\" >2</td>\n",
       "      <td id=\"T_8f1cc_row10_col2\" class=\"data row10 col2\" >2528</td>\n",
       "      <td id=\"T_8f1cc_row10_col3\" class=\"data row10 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row10_col4\" class=\"data row10 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row11_col0\" class=\"data row11 col0\" >c3</td>\n",
       "      <td id=\"T_8f1cc_row11_col1\" class=\"data row11 col1\" >3</td>\n",
       "      <td id=\"T_8f1cc_row11_col2\" class=\"data row11 col2\" >2435</td>\n",
       "      <td id=\"T_8f1cc_row11_col3\" class=\"data row11 col3\" >1</td>\n",
       "      <td id=\"T_8f1cc_row11_col4\" class=\"data row11 col4\" >0.0411%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row12_col0\" class=\"data row12 col0\" >c3</td>\n",
       "      <td id=\"T_8f1cc_row12_col1\" class=\"data row12 col1\" >4</td>\n",
       "      <td id=\"T_8f1cc_row12_col2\" class=\"data row12 col2\" >2496</td>\n",
       "      <td id=\"T_8f1cc_row12_col3\" class=\"data row12 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row12_col4\" class=\"data row12 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row13_col0\" class=\"data row13 col0\" >c3</td>\n",
       "      <td id=\"T_8f1cc_row13_col1\" class=\"data row13 col1\" >5</td>\n",
       "      <td id=\"T_8f1cc_row13_col2\" class=\"data row13 col2\" >2451</td>\n",
       "      <td id=\"T_8f1cc_row13_col3\" class=\"data row13 col3\" >1</td>\n",
       "      <td id=\"T_8f1cc_row13_col4\" class=\"data row13 col4\" >0.0408%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row14_col0\" class=\"data row14 col0\" >c3</td>\n",
       "      <td id=\"T_8f1cc_row14_col1\" class=\"data row14 col1\" >6</td>\n",
       "      <td id=\"T_8f1cc_row14_col2\" class=\"data row14 col2\" >2504</td>\n",
       "      <td id=\"T_8f1cc_row14_col3\" class=\"data row14 col3\" >1</td>\n",
       "      <td id=\"T_8f1cc_row14_col4\" class=\"data row14 col4\" >0.0399%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row15_col0\" class=\"data row15 col0\" >c3</td>\n",
       "      <td id=\"T_8f1cc_row15_col1\" class=\"data row15 col1\" >7</td>\n",
       "      <td id=\"T_8f1cc_row15_col2\" class=\"data row15 col2\" >2490</td>\n",
       "      <td id=\"T_8f1cc_row15_col3\" class=\"data row15 col3\" >5</td>\n",
       "      <td id=\"T_8f1cc_row15_col4\" class=\"data row15 col4\" >0.2008%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row16_col0\" class=\"data row16 col0\" >f5</td>\n",
       "      <td id=\"T_8f1cc_row16_col1\" class=\"data row16 col1\" >0</td>\n",
       "      <td id=\"T_8f1cc_row16_col2\" class=\"data row16 col2\" >2462</td>\n",
       "      <td id=\"T_8f1cc_row16_col3\" class=\"data row16 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row16_col4\" class=\"data row16 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row17_col0\" class=\"data row17 col0\" >f5</td>\n",
       "      <td id=\"T_8f1cc_row17_col1\" class=\"data row17 col1\" >1</td>\n",
       "      <td id=\"T_8f1cc_row17_col2\" class=\"data row17 col2\" >2457</td>\n",
       "      <td id=\"T_8f1cc_row17_col3\" class=\"data row17 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row17_col4\" class=\"data row17 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row18_col0\" class=\"data row18 col0\" >f5</td>\n",
       "      <td id=\"T_8f1cc_row18_col1\" class=\"data row18 col1\" >2</td>\n",
       "      <td id=\"T_8f1cc_row18_col2\" class=\"data row18 col2\" >2400</td>\n",
       "      <td id=\"T_8f1cc_row18_col3\" class=\"data row18 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row18_col4\" class=\"data row18 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row19_col0\" class=\"data row19 col0\" >f5</td>\n",
       "      <td id=\"T_8f1cc_row19_col1\" class=\"data row19 col1\" >3</td>\n",
       "      <td id=\"T_8f1cc_row19_col2\" class=\"data row19 col2\" >2534</td>\n",
       "      <td id=\"T_8f1cc_row19_col3\" class=\"data row19 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row19_col4\" class=\"data row19 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row20_col0\" class=\"data row20 col0\" >f5</td>\n",
       "      <td id=\"T_8f1cc_row20_col1\" class=\"data row20 col1\" >4</td>\n",
       "      <td id=\"T_8f1cc_row20_col2\" class=\"data row20 col2\" >2555</td>\n",
       "      <td id=\"T_8f1cc_row20_col3\" class=\"data row20 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row20_col4\" class=\"data row20 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row21_col0\" class=\"data row21 col0\" >f5</td>\n",
       "      <td id=\"T_8f1cc_row21_col1\" class=\"data row21 col1\" >5</td>\n",
       "      <td id=\"T_8f1cc_row21_col2\" class=\"data row21 col2\" >2529</td>\n",
       "      <td id=\"T_8f1cc_row21_col3\" class=\"data row21 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row21_col4\" class=\"data row21 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row22_col0\" class=\"data row22 col0\" >f5</td>\n",
       "      <td id=\"T_8f1cc_row22_col1\" class=\"data row22 col1\" >6</td>\n",
       "      <td id=\"T_8f1cc_row22_col2\" class=\"data row22 col2\" >2525</td>\n",
       "      <td id=\"T_8f1cc_row22_col3\" class=\"data row22 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row22_col4\" class=\"data row22 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row23_col0\" class=\"data row23 col0\" >f5</td>\n",
       "      <td id=\"T_8f1cc_row23_col1\" class=\"data row23 col1\" >7</td>\n",
       "      <td id=\"T_8f1cc_row23_col2\" class=\"data row23 col2\" >2465</td>\n",
       "      <td id=\"T_8f1cc_row23_col3\" class=\"data row23 col3\" >1</td>\n",
       "      <td id=\"T_8f1cc_row23_col4\" class=\"data row23 col4\" >0.0406%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row24_col0\" class=\"data row24 col0\" >f6</td>\n",
       "      <td id=\"T_8f1cc_row24_col1\" class=\"data row24 col1\" >0</td>\n",
       "      <td id=\"T_8f1cc_row24_col2\" class=\"data row24 col2\" >2420</td>\n",
       "      <td id=\"T_8f1cc_row24_col3\" class=\"data row24 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row24_col4\" class=\"data row24 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row25_col0\" class=\"data row25 col0\" >f6</td>\n",
       "      <td id=\"T_8f1cc_row25_col1\" class=\"data row25 col1\" >1</td>\n",
       "      <td id=\"T_8f1cc_row25_col2\" class=\"data row25 col2\" >2563</td>\n",
       "      <td id=\"T_8f1cc_row25_col3\" class=\"data row25 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row25_col4\" class=\"data row25 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row26_col0\" class=\"data row26 col0\" >f6</td>\n",
       "      <td id=\"T_8f1cc_row26_col1\" class=\"data row26 col1\" >2</td>\n",
       "      <td id=\"T_8f1cc_row26_col2\" class=\"data row26 col2\" >2550</td>\n",
       "      <td id=\"T_8f1cc_row26_col3\" class=\"data row26 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row26_col4\" class=\"data row26 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row27_col0\" class=\"data row27 col0\" >f6</td>\n",
       "      <td id=\"T_8f1cc_row27_col1\" class=\"data row27 col1\" >3</td>\n",
       "      <td id=\"T_8f1cc_row27_col2\" class=\"data row27 col2\" >2498</td>\n",
       "      <td id=\"T_8f1cc_row27_col3\" class=\"data row27 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row27_col4\" class=\"data row27 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row28_col0\" class=\"data row28 col0\" >f6</td>\n",
       "      <td id=\"T_8f1cc_row28_col1\" class=\"data row28 col1\" >4</td>\n",
       "      <td id=\"T_8f1cc_row28_col2\" class=\"data row28 col2\" >2471</td>\n",
       "      <td id=\"T_8f1cc_row28_col3\" class=\"data row28 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row28_col4\" class=\"data row28 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row29_col0\" class=\"data row29 col0\" >f6</td>\n",
       "      <td id=\"T_8f1cc_row29_col1\" class=\"data row29 col1\" >5</td>\n",
       "      <td id=\"T_8f1cc_row29_col2\" class=\"data row29 col2\" >2636</td>\n",
       "      <td id=\"T_8f1cc_row29_col3\" class=\"data row29 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row29_col4\" class=\"data row29 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row30_col0\" class=\"data row30 col0\" >f6</td>\n",
       "      <td id=\"T_8f1cc_row30_col1\" class=\"data row30 col1\" >6</td>\n",
       "      <td id=\"T_8f1cc_row30_col2\" class=\"data row30 col2\" >2506</td>\n",
       "      <td id=\"T_8f1cc_row30_col3\" class=\"data row30 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row30_col4\" class=\"data row30 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row31_col0\" class=\"data row31 col0\" >f6</td>\n",
       "      <td id=\"T_8f1cc_row31_col1\" class=\"data row31 col1\" >7</td>\n",
       "      <td id=\"T_8f1cc_row31_col2\" class=\"data row31 col2\" >2529</td>\n",
       "      <td id=\"T_8f1cc_row31_col3\" class=\"data row31 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row31_col4\" class=\"data row31 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row32_col0\" class=\"data row32 col0\" >f7</td>\n",
       "      <td id=\"T_8f1cc_row32_col1\" class=\"data row32 col1\" >0</td>\n",
       "      <td id=\"T_8f1cc_row32_col2\" class=\"data row32 col2\" >2483</td>\n",
       "      <td id=\"T_8f1cc_row32_col3\" class=\"data row32 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row32_col4\" class=\"data row32 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row33_col0\" class=\"data row33 col0\" >f7</td>\n",
       "      <td id=\"T_8f1cc_row33_col1\" class=\"data row33 col1\" >1</td>\n",
       "      <td id=\"T_8f1cc_row33_col2\" class=\"data row33 col2\" >2454</td>\n",
       "      <td id=\"T_8f1cc_row33_col3\" class=\"data row33 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row33_col4\" class=\"data row33 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row34_col0\" class=\"data row34 col0\" >f7</td>\n",
       "      <td id=\"T_8f1cc_row34_col1\" class=\"data row34 col1\" >2</td>\n",
       "      <td id=\"T_8f1cc_row34_col2\" class=\"data row34 col2\" >2566</td>\n",
       "      <td id=\"T_8f1cc_row34_col3\" class=\"data row34 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row34_col4\" class=\"data row34 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row35_col0\" class=\"data row35 col0\" >f7</td>\n",
       "      <td id=\"T_8f1cc_row35_col1\" class=\"data row35 col1\" >3</td>\n",
       "      <td id=\"T_8f1cc_row35_col2\" class=\"data row35 col2\" >2403</td>\n",
       "      <td id=\"T_8f1cc_row35_col3\" class=\"data row35 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row35_col4\" class=\"data row35 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row36_col0\" class=\"data row36 col0\" >f7</td>\n",
       "      <td id=\"T_8f1cc_row36_col1\" class=\"data row36 col1\" >4</td>\n",
       "      <td id=\"T_8f1cc_row36_col2\" class=\"data row36 col2\" >2518</td>\n",
       "      <td id=\"T_8f1cc_row36_col3\" class=\"data row36 col3\" >0</td>\n",
       "      <td id=\"T_8f1cc_row36_col4\" class=\"data row36 col4\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row37_col0\" class=\"data row37 col0\" >f7</td>\n",
       "      <td id=\"T_8f1cc_row37_col1\" class=\"data row37 col1\" >5</td>\n",
       "      <td id=\"T_8f1cc_row37_col2\" class=\"data row37 col2\" >2502</td>\n",
       "      <td id=\"T_8f1cc_row37_col3\" class=\"data row37 col3\" >2</td>\n",
       "      <td id=\"T_8f1cc_row37_col4\" class=\"data row37 col4\" >0.0799%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row38_col0\" class=\"data row38 col0\" >f7</td>\n",
       "      <td id=\"T_8f1cc_row38_col1\" class=\"data row38 col1\" >6</td>\n",
       "      <td id=\"T_8f1cc_row38_col2\" class=\"data row38 col2\" >2425</td>\n",
       "      <td id=\"T_8f1cc_row38_col3\" class=\"data row38 col3\" >2</td>\n",
       "      <td id=\"T_8f1cc_row38_col4\" class=\"data row38 col4\" >0.0825%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8f1cc_row39_col0\" class=\"data row39 col0\" >f7</td>\n",
       "      <td id=\"T_8f1cc_row39_col1\" class=\"data row39 col1\" >7</td>\n",
       "      <td id=\"T_8f1cc_row39_col2\" class=\"data row39 col2\" >2474</td>\n",
       "      <td id=\"T_8f1cc_row39_col3\" class=\"data row39 col3\" >21</td>\n",
       "      <td id=\"T_8f1cc_row39_col4\" class=\"data row39 col4\" >0.8488%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff2f700090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the fault injection results\n",
    "df_rand = pd.read_csv(\"results.csv\")\n",
    "\n",
    "# Group by layer and bit position, and calculate samples, errors, and error ratio\n",
    "table_4 = (\n",
    "    df_rand.groupby([\"layer\", \"bit_position\"])\n",
    "    .agg(\n",
    "        samples=(\"original_output\", \"count\"),  # Total bit flips (Samples)\n",
    "        errors=(\n",
    "            \"original_output\",\n",
    "            lambda x: (x != df_rand.loc[x.index, \"flipped_output\"]).sum(),\n",
    "        ),  # Total Errors\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate Error Ratio\n",
    "table_4[\"error_ratio\"] = table_4[\"errors\"] / table_4[\"samples\"]\n",
    "\n",
    "table_4[\"error_ratio\"] = (table_4[\"error_ratio\"] * 100).round(4).astype(str) + \"%\"\n",
    "\n",
    "# Sort the table for better readability\n",
    "table_4 = table_4.sort_values(by=[\"layer\", \"bit_position\"])\n",
    "\n",
    "# Save or display the results\n",
    "table_4.to_csv(\"table_4.csv\", index=False)\n",
    "print(\"Table 4 saved as 'table_4.csv'.\")\n",
    "display(table_4.style.hide(axis=\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate table for the impact of bit position across all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bit position impact table saved as 'bit_position_impact.csv'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_08a93\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_08a93_level0_col0\" class=\"col_heading level0 col0\" >bit_position</th>\n",
       "      <th id=\"T_08a93_level0_col1\" class=\"col_heading level0 col1\" >samples</th>\n",
       "      <th id=\"T_08a93_level0_col2\" class=\"col_heading level0 col2\" >errors</th>\n",
       "      <th id=\"T_08a93_level0_col3\" class=\"col_heading level0 col3\" >error_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_08a93_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_08a93_row0_col1\" class=\"data row0 col1\" >12410</td>\n",
       "      <td id=\"T_08a93_row0_col2\" class=\"data row0 col2\" >4</td>\n",
       "      <td id=\"T_08a93_row0_col3\" class=\"data row0 col3\" >0.0322%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_08a93_row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "      <td id=\"T_08a93_row1_col1\" class=\"data row1 col1\" >12586</td>\n",
       "      <td id=\"T_08a93_row1_col2\" class=\"data row1 col2\" >7</td>\n",
       "      <td id=\"T_08a93_row1_col3\" class=\"data row1 col3\" >0.0556%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_08a93_row2_col0\" class=\"data row2 col0\" >2</td>\n",
       "      <td id=\"T_08a93_row2_col1\" class=\"data row2 col1\" >12622</td>\n",
       "      <td id=\"T_08a93_row2_col2\" class=\"data row2 col2\" >5</td>\n",
       "      <td id=\"T_08a93_row2_col3\" class=\"data row2 col3\" >0.0396%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_08a93_row3_col0\" class=\"data row3 col0\" >3</td>\n",
       "      <td id=\"T_08a93_row3_col1\" class=\"data row3 col1\" >12375</td>\n",
       "      <td id=\"T_08a93_row3_col2\" class=\"data row3 col2\" >13</td>\n",
       "      <td id=\"T_08a93_row3_col3\" class=\"data row3 col3\" >0.1051%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_08a93_row4_col0\" class=\"data row4 col0\" >4</td>\n",
       "      <td id=\"T_08a93_row4_col1\" class=\"data row4 col1\" >12492</td>\n",
       "      <td id=\"T_08a93_row4_col2\" class=\"data row4 col2\" >8</td>\n",
       "      <td id=\"T_08a93_row4_col3\" class=\"data row4 col3\" >0.064%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_08a93_row5_col0\" class=\"data row5 col0\" >5</td>\n",
       "      <td id=\"T_08a93_row5_col1\" class=\"data row5 col1\" >12617</td>\n",
       "      <td id=\"T_08a93_row5_col2\" class=\"data row5 col2\" >16</td>\n",
       "      <td id=\"T_08a93_row5_col3\" class=\"data row5 col3\" >0.1268%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_08a93_row6_col0\" class=\"data row6 col0\" >6</td>\n",
       "      <td id=\"T_08a93_row6_col1\" class=\"data row6 col1\" >12435</td>\n",
       "      <td id=\"T_08a93_row6_col2\" class=\"data row6 col2\" >20</td>\n",
       "      <td id=\"T_08a93_row6_col3\" class=\"data row6 col3\" >0.1608%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_08a93_row7_col0\" class=\"data row7 col0\" >7</td>\n",
       "      <td id=\"T_08a93_row7_col1\" class=\"data row7 col1\" >12463</td>\n",
       "      <td id=\"T_08a93_row7_col2\" class=\"data row7 col2\" >48</td>\n",
       "      <td id=\"T_08a93_row7_col3\" class=\"data row7 col3\" >0.3851%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff2f703dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the fault injection results\n",
    "df_rand = pd.read_csv(\"results.csv\")\n",
    "\n",
    "# Group by bit position and calculate samples, errors, and error ratio\n",
    "bit_position_impact = (\n",
    "    df_rand.groupby(\"bit_position\")\n",
    "    .agg(\n",
    "        samples=(\"original_output\", \"count\"),  # Total bit flips for each bit position\n",
    "        errors=(\n",
    "            \"original_output\",\n",
    "            lambda x: (x != df_rand.loc[x.index, \"flipped_output\"]).sum(),\n",
    "        ),  # Total errors for each bit position\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate error ratio\n",
    "bit_position_impact[\"error_ratio\"] = bit_position_impact[\"errors\"] / bit_position_impact[\"samples\"]\n",
    "\n",
    "bit_position_impact[\"error_ratio\"] = (bit_position_impact[\"error_ratio\"] * 100).round(4).astype(str) + \"%\"\n",
    "\n",
    "# Sort the table for readability (ascending order of bit position)\n",
    "bit_position_impact = bit_position_impact.sort_values(by=\"bit_position\")\n",
    "\n",
    "# Save or display the results\n",
    "bit_position_impact.to_csv(\"bit_position_impact.csv\", index=False)\n",
    "print(\"Bit position impact table saved as 'bit_position_impact.csv'.\")\n",
    "display(bit_position_impact.style.hide(axis=\"index\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate table for the impact of layers across all bit positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer impact table saved as 'layer_impact.csv'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_46ed2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_46ed2_level0_col0\" class=\"col_heading level0 col0\" >layer</th>\n",
       "      <th id=\"T_46ed2_level0_col1\" class=\"col_heading level0 col1\" >samples</th>\n",
       "      <th id=\"T_46ed2_level0_col2\" class=\"col_heading level0 col2\" >errors</th>\n",
       "      <th id=\"T_46ed2_level0_col3\" class=\"col_heading level0 col3\" >error_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_46ed2_row0_col0\" class=\"data row0 col0\" >c1</td>\n",
       "      <td id=\"T_46ed2_row0_col1\" class=\"data row0 col1\" >20136</td>\n",
       "      <td id=\"T_46ed2_row0_col2\" class=\"data row0 col2\" >87</td>\n",
       "      <td id=\"T_46ed2_row0_col3\" class=\"data row0 col3\" >0.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_46ed2_row1_col0\" class=\"data row1 col0\" >c3</td>\n",
       "      <td id=\"T_46ed2_row1_col1\" class=\"data row1 col1\" >19939</td>\n",
       "      <td id=\"T_46ed2_row1_col2\" class=\"data row1 col2\" >8</td>\n",
       "      <td id=\"T_46ed2_row1_col3\" class=\"data row1 col3\" >0.04%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_46ed2_row2_col0\" class=\"data row2 col0\" >f5</td>\n",
       "      <td id=\"T_46ed2_row2_col1\" class=\"data row2 col1\" >19927</td>\n",
       "      <td id=\"T_46ed2_row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "      <td id=\"T_46ed2_row2_col3\" class=\"data row2 col3\" >0.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_46ed2_row3_col0\" class=\"data row3 col0\" >f6</td>\n",
       "      <td id=\"T_46ed2_row3_col1\" class=\"data row3 col1\" >20173</td>\n",
       "      <td id=\"T_46ed2_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "      <td id=\"T_46ed2_row3_col3\" class=\"data row3 col3\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_46ed2_row4_col0\" class=\"data row4 col0\" >f7</td>\n",
       "      <td id=\"T_46ed2_row4_col1\" class=\"data row4 col1\" >19825</td>\n",
       "      <td id=\"T_46ed2_row4_col2\" class=\"data row4 col2\" >25</td>\n",
       "      <td id=\"T_46ed2_row4_col3\" class=\"data row4 col3\" >0.13%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff2f6d30d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the fault injection results\n",
    "df_rand = pd.read_csv(\"results.csv\")\n",
    "\n",
    "# Group by layer and calculate samples, errors, and error ratio\n",
    "layer_impact = (\n",
    "    df_rand.groupby(\"layer\")\n",
    "    .agg(\n",
    "        samples=(\"original_output\", \"count\"),  # Total bit flips for each layer\n",
    "        errors=(\n",
    "            \"original_output\",\n",
    "            lambda x: (x != df_rand.loc[x.index, \"flipped_output\"]).sum(),\n",
    "        ),  # Total errors for each layer\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate error ratio\n",
    "layer_impact[\"error_ratio\"] = layer_impact[\"errors\"] / layer_impact[\"samples\"]\n",
    "\n",
    "layer_impact[\"error_ratio\"] = (layer_impact[\"error_ratio\"] * 100).round(4).astype(str) + \"%\"\n",
    "\n",
    "# Sort the table for readability (ascending order of layers)\n",
    "layer_impact = layer_impact.sort_values(by=\"layer\")\n",
    "\n",
    "# Save or display the results\n",
    "layer_impact.to_csv(\"layer_impact.csv\", index=False)\n",
    "print(\"Layer impact table saved as 'layer_impact.csv'.\")\n",
    "display(layer_impact.style.hide(axis=\"index\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flip direction table saved as 'flip_direction_table.csv'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4d313\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_4d313_level0_col0\" class=\"col_heading level0 col0\" >flip_direction</th>\n",
       "      <th id=\"T_4d313_level0_col1\" class=\"col_heading level0 col1\" >samples</th>\n",
       "      <th id=\"T_4d313_level0_col2\" class=\"col_heading level0 col2\" >errors</th>\n",
       "      <th id=\"T_4d313_level0_col3\" class=\"col_heading level0 col3\" >error_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_4d313_row0_col0\" class=\"data row0 col0\" >0 to 1</td>\n",
       "      <td id=\"T_4d313_row0_col1\" class=\"data row0 col1\" >48189</td>\n",
       "      <td id=\"T_4d313_row0_col2\" class=\"data row0 col2\" >58</td>\n",
       "      <td id=\"T_4d313_row0_col3\" class=\"data row0 col3\" >0.1204%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4d313_row1_col0\" class=\"data row1 col0\" >1 to 0</td>\n",
       "      <td id=\"T_4d313_row1_col1\" class=\"data row1 col1\" >51811</td>\n",
       "      <td id=\"T_4d313_row1_col2\" class=\"data row1 col2\" >63</td>\n",
       "      <td id=\"T_4d313_row1_col3\" class=\"data row1 col3\" >0.1216%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff2fdaf810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group by flip direction and calculate samples, errors, and error ratio\n",
    "flip_direction_table = (\n",
    "    df_rand.groupby([\"original_bit\", \"flipped_bit\"])\n",
    "    .agg(\n",
    "        samples=(\"original_output\", \"count\"),  # Total bit flips for each direction\n",
    "        errors=(\n",
    "            \"original_output\",\n",
    "            lambda x: (x != df_rand.loc[x.index, \"flipped_output\"]).sum(),\n",
    "        ),  # Total errors for each direction\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Create a new column for flip direction as a string (e.g., \"0 to 1\", \"1 to 0\")\n",
    "flip_direction_table[\"flip_direction\"] = (\n",
    "    flip_direction_table[\"original_bit\"].astype(str)\n",
    "    + \" to \"\n",
    "    + flip_direction_table[\"flipped_bit\"].astype(str)\n",
    ")\n",
    "\n",
    "# Calculate error ratio as a percentage and format\n",
    "flip_direction_table[\"error_ratio\"] = (\n",
    "    (flip_direction_table[\"errors\"] / flip_direction_table[\"samples\"]) * 100\n",
    ").round(4).astype(str) + \"%\"\n",
    "\n",
    "# Drop the original_bit and flipped_bit columns for cleaner display\n",
    "flip_direction_table = flip_direction_table[[\"flip_direction\", \"samples\", \"errors\", \"error_ratio\"]]\n",
    "\n",
    "# Save or display the results\n",
    "flip_direction_table.to_csv(\"flip_direction_table.csv\", index=False)\n",
    "print(\"Flip direction table saved as 'flip_direction_table.csv'.\")\n",
    "display(flip_direction_table.style.hide(axis=\"index\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs the same bit-flip testing as before, but instead of randomly selecting layer and bit position, it specifically targets bit position 5 in the first convolutional layer (c1) of the network, allowing for focused analysis of faults in a specific network location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "TARGET_LAYER = \"c1\"\n",
    "TARGET_BIT_POS = 5\n",
    "\n",
    "results_c1_5 = []\n",
    "orig_sd = flenet.state_dict()\n",
    "\n",
    "for inputs, targets in exp_loader:\n",
    "    for input, target in zip(inputs, targets):\n",
    "        input = input.unsqueeze(0)\n",
    "        output = infer(input, flenet)\n",
    "\n",
    "        sd = copy.deepcopy(orig_sd)\n",
    "\n",
    "        layer = get_weight_key(flenet, TARGET_LAYER)\n",
    "        params = to_tensor(sd[layer])\n",
    "        idx = randidx(params)\n",
    "        param = params[idx]\n",
    "\n",
    "        orig_param = quant_to_int8(param)\n",
    "\n",
    "        bit_pos = TARGET_BIT_POS\n",
    "        orig_bit = get_bit(orig_param, bit_pos)\n",
    "        flipped_bit = 1 if orig_bit == 0 else 0\n",
    "\n",
    "        flipped_param = flip_bit(orig_param, bit_pos)\n",
    "\n",
    "        params[idx] = int8_to_quant(\n",
    "            flipped_param, param.q_scale(), param.q_zero_point()\n",
    "        )\n",
    "\n",
    "        flenet.load_state_dict(sd)\n",
    "\n",
    "        flip_output = infer(input, flenet)\n",
    "\n",
    "        results_c1_5.append(\n",
    "            {\n",
    "                \"layer\": clean_layer(layer),\n",
    "                \"bit_position\": bit_pos,\n",
    "                \"original_bit\": orig_bit,\n",
    "                \"flipped_bit\": flipped_bit,\n",
    "                \"original_param\": orig_param,\n",
    "                \"flipped_param\": flipped_param,\n",
    "                \"original_output\": output.item(),\n",
    "                \"flipped_output\": flip_output.item(),\n",
    "                \"target_output\": target.item(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        flenet.load_state_dict(orig_sd)\n",
    "\n",
    "df_c1_5 = pd.DataFrame(results_c1_5)\n",
    "df_c1_5.to_csv(\"results_c1_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>bit_position</th>\n",
       "      <th>original_bit</th>\n",
       "      <th>flipped_bit</th>\n",
       "      <th>original_param</th>\n",
       "      <th>flipped_param</th>\n",
       "      <th>original_output</th>\n",
       "      <th>flipped_output</th>\n",
       "      <th>target_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-41</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-97</td>\n",
       "      <td>-65</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-102</td>\n",
       "      <td>-70</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-24</td>\n",
       "      <td>-56</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-36</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-34</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-12</td>\n",
       "      <td>-44</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>117</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-64</td>\n",
       "      <td>-32</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-33</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3893</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-13</td>\n",
       "      <td>-45</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4248</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-34</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4761</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-43</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6011</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-20</td>\n",
       "      <td>-52</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-17</td>\n",
       "      <td>-49</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6578</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6625</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-40</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-32</td>\n",
       "      <td>-64</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7856</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7905</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8332</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-32</td>\n",
       "      <td>-64</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9777</th>\n",
       "      <td>c1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-35</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     layer  bit_position  original_bit  flipped_bit original_param  \\\n",
       "287     c1             5             1            0             -9   \n",
       "359     c1             5             0            1            -97   \n",
       "435     c1             5             1            0             54   \n",
       "659     c1             5             0            1              6   \n",
       "916     c1             5             0            1             12   \n",
       "1248    c1             5             1            0             63   \n",
       "1364    c1             5             0            1           -102   \n",
       "1822    c1             5             0            1             29   \n",
       "2189    c1             5             1            0            -24   \n",
       "2280    c1             5             1            0             -4   \n",
       "2414    c1             5             1            0             -2   \n",
       "2695    c1             5             1            0            -12   \n",
       "2721    c1             5             0            1             85   \n",
       "2836    c1             5             1            0             97   \n",
       "2959    c1             5             0            1            -64   \n",
       "3005    c1             5             1            0             -1   \n",
       "3288    c1             5             0            1              3   \n",
       "3441    c1             5             1            0             40   \n",
       "3749    c1             5             0            1             87   \n",
       "3893    c1             5             0            1              6   \n",
       "4078    c1             5             1            0            -13   \n",
       "4223    c1             5             0            1             21   \n",
       "4248    c1             5             1            0             -2   \n",
       "4455    c1             5             1            0             36   \n",
       "4500    c1             5             0            1             29   \n",
       "4731    c1             5             0            1              8   \n",
       "4761    c1             5             1            0             97   \n",
       "4783    c1             5             1            0            -11   \n",
       "6011    c1             5             1            0            -20   \n",
       "6173    c1             5             1            0            -17   \n",
       "6578    c1             5             0            1             12   \n",
       "6625    c1             5             1            0             -8   \n",
       "7216    c1             5             1            0            -32   \n",
       "7856    c1             5             0            1             22   \n",
       "7905    c1             5             1            0             57   \n",
       "8332    c1             5             1            0            -32   \n",
       "8527    c1             5             1            0             51   \n",
       "9777    c1             5             0            1            -35   \n",
       "\n",
       "      flipped_param  original_output  flipped_output  target_output  \n",
       "287             -41                2               4              4  \n",
       "359             -65                4               9              9  \n",
       "435              22                9               8              8  \n",
       "659              38                1               7              2  \n",
       "916              44                4               2              4  \n",
       "1248             31                2               8              8  \n",
       "1364            -70                2               8              8  \n",
       "1822             61                6               5              6  \n",
       "2189            -56                9               7              9  \n",
       "2280            -36                3               0              3  \n",
       "2414            -34                4               8              9  \n",
       "2695            -44                7               3              7  \n",
       "2721            117                6               5              6  \n",
       "2836             65                2               4              4  \n",
       "2959            -32                3               2              2  \n",
       "3005            -33                9               4              9  \n",
       "3288             35                9               4              4  \n",
       "3441              8                7               2              7  \n",
       "3749            119                0               6              6  \n",
       "3893             38                8               5              5  \n",
       "4078            -45                9               8              9  \n",
       "4223             53                4               2              4  \n",
       "4248            -34                2               0              2  \n",
       "4455              4                8               0              8  \n",
       "4500             61                9               1              9  \n",
       "4731             40                2               7              8  \n",
       "4761             65                4               7              9  \n",
       "4783            -43                4               9              4  \n",
       "6011            -52                3               8              3  \n",
       "6173            -49                4               8              9  \n",
       "6578             44                5               8              8  \n",
       "6625            -40                0               2              8  \n",
       "7216            -64                6               0              0  \n",
       "7856             54                8               1              1  \n",
       "7905             25                2               3              3  \n",
       "8332            -64                9               1              9  \n",
       "8527             19                9               4              4  \n",
       "9777             -3                3               5              5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_5_errors_df = df_c1_5[df_c1_5[\"original_output\"] != df_c1_5[\"flipped_output\"]]\n",
    "\n",
    "c1_5_errors_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
